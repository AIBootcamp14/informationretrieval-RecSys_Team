"""
ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” Validation Set ìƒì„± ë„êµ¬

í•µì‹¬ ê°œì„ :
1. ìƒ˜í”Œ í¬ê¸°: 20ê°œ â†’ 50~100ê°œ (ì „ì²´ì˜ 23~45%)
2. ë‚œì´ë„ë³„ ê· í˜•: ì‰¬ì›€/ì¤‘ê°„/ì–´ë ¤ì›€ (BM25 ì ìˆ˜ ê¸°ë°˜)
3. ë¬¸ì„œ ë‚´ìš© ì§ì ‘ í‘œì‹œ (ì²˜ìŒ 500ì)
4. ì‹ ë¢°ë„ ë ˆë²¨ ë¶€ì—¬
"""

import json
import random
from elasticsearch import Elasticsearch
from collections import defaultdict

es = Elasticsearch(['http://localhost:9200'])

SMALLTALK_IDS = {
    276, 261, 233, 90, 222, 235, 165, 153, 169, 141, 183
}

def categorize_queries_by_difficulty():
    """
    BM25 ì ìˆ˜ ê¸°ë°˜ìœ¼ë¡œ ì¿¼ë¦¬ ë‚œì´ë„ ë¶„ë¥˜
    """
    with open('../data/eval.jsonl', 'r') as f:
        eval_data = [json.loads(line) for line in f]

    categories = {
        'easy': [],      # max_score >= 15
        'medium': [],    # 8 <= max_score < 15
        'hard': [],      # 3 <= max_score < 8
        'very_hard': [], # max_score < 3 (ì¼ë°˜ ëŒ€í™” ì œì™¸)
        'smalltalk': []
    }

    print("\në‚œì´ë„ ë¶„ë¥˜ ì¤‘...")

    for item in eval_data:
        eval_id = item['eval_id']

        # ì¼ë°˜ ëŒ€í™”
        if eval_id in SMALLTALK_IDS:
            categories['smalltalk'].append(item)
            continue

        # ì¿¼ë¦¬ ì¶”ì¶œ
        if isinstance(item['msg'], list):
            query = item['msg'][-1]['content']
        else:
            query = item['msg']

        # BM25 ê²€ìƒ‰
        response = es.search(
            index='test',
            body={
                'query': {
                    'match': {
                        'content': {
                            'query': query,
                            'analyzer': 'nori'
                        }
                    }
                },
                'size': 1
            }
        )

        if not response['hits']['hits']:
            max_score = 0.0
        else:
            max_score = response['hits']['hits'][0]['_score']

        # ë‚œì´ë„ ë¶„ë¥˜
        item['max_score'] = max_score

        if max_score >= 15:
            categories['easy'].append(item)
        elif max_score >= 8:
            categories['medium'].append(item)
        elif max_score >= 3:
            categories['hard'].append(item)
        else:
            categories['very_hard'].append(item)

    print(f"\në‚œì´ë„ë³„ ë¶„í¬:")
    print(f"  Easy (â‰¥15): {len(categories['easy'])}ê°œ")
    print(f"  Medium (8~15): {len(categories['medium'])}ê°œ")
    print(f"  Hard (3~8): {len(categories['hard'])}ê°œ")
    print(f"  Very Hard (<3): {len(categories['very_hard'])}ê°œ")
    print(f"  Smalltalk: {len(categories['smalltalk'])}ê°œ")

    return categories

def stratified_sample(categories, total_samples=220):
    """
    ì „ì²´ ìƒ˜í”Œ ì‚¬ìš© (220ê°œ)

    ëª¨ë“  ì¿¼ë¦¬ë¥¼ validation setìœ¼ë¡œ ì‚¬ìš©
    - ì™„ë²½í•œ ë¡œì»¬ í…ŒìŠ¤íŠ¸ í™˜ê²½ êµ¬ì¶•
    - Validation MAP = Leaderboard MAP
    """
    samples = []

    # ëª¨ë“  ì¹´í…Œê³ ë¦¬ì˜ ëª¨ë“  ì¿¼ë¦¬ ì‚¬ìš©
    samples.extend(categories['easy'])
    samples.extend(categories['medium'])
    samples.extend(categories['hard'])
    samples.extend(categories['very_hard'])
    samples.extend(categories['smalltalk'])

    # ì…”í”Œ
    random.shuffle(samples)

    print(f"\nâœ… ì „ì²´ {len(samples)}ê°œ ì‚¬ìš© (100%)")
    print(f"  - Easy: {len(categories['easy'])}ê°œ")
    print(f"  - Medium: {len(categories['medium'])}ê°œ")
    print(f"  - Hard: {len(categories['hard'])}ê°œ")
    print(f"  - Very Hard: {len(categories['very_hard'])}ê°œ")
    print(f"  - Smalltalk: {len(categories['smalltalk'])}ê°œ")

    return samples

def search_and_display_detailed(es, query, eval_id, top_k=10):
    """
    ê²€ìƒ‰ ê²°ê³¼ë¥¼ ìƒì„¸íˆ í‘œì‹œ (ë¬¸ì„œ ë‚´ìš© í¬í•¨)
    """
    response = es.search(
        index='test',
        body={
            'query': {
                'match': {
                    'content': {
                        'query': query,
                        'analyzer': 'nori'
                    }
                }
            },
            'size': top_k
        }
    )

    print(f"\n{'='*80}")
    print(f"Query (ID {eval_id}): {query}")
    print(f"{'='*80}")

    results = []

    if not response['hits']['hits']:
        print("\nâš ï¸ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
        return results

    for i, hit in enumerate(response['hits']['hits'], 1):
        docid = hit['_source']['docid']
        score = hit['_score']
        content = hit['_source']['content']

        print(f"\n[{i}] Score: {score:.2f} | DocID: {docid[:36]}")
        print(f"Content (ì²˜ìŒ 500ì):")
        print(f"{content[:500]}...")
        print(f"-" * 80)

        results.append({
            'docid': docid,
            'score': score,
            'content': content
        })

    return results

def annotate_with_confidence(samples):
    """
    ìƒ˜í”Œì— ì •ë‹µ ë ˆì´ë¸” + ì‹ ë¢°ë„ ì¶”ê°€
    """
    annotated = []

    print(f"\n{'#'*80}")
    print(f"ìˆ˜ë™ Annotation ì‹œì‘ ({len(samples)}ê°œ)")
    print(f"{'#'*80}")

    for idx, item in enumerate(samples, 1):
        eval_id = item['eval_id']

        # ì¿¼ë¦¬ ì¶”ì¶œ
        if isinstance(item['msg'], list):
            query = item['msg'][-1]['content']
            # ë©€í‹°í„´ì¸ ê²½ìš° ì´ì „ ëŒ€í™” í‘œì‹œ
            if len(item['msg']) > 1:
                print(f"\n[ì´ì „ ëŒ€í™”]")
                for msg in item['msg'][:-1]:
                    role = "ğŸ‘¤" if msg['role'] == 'user' else "ğŸ¤–"
                    print(f"  {role} {msg['content']}")
        else:
            query = item['msg']

        print(f"\n\n{'#'*80}")
        print(f"[{idx}/{len(samples)}] ì§„í–‰ë¥ : {idx/len(samples)*100:.1f}%")
        print(f"{'#'*80}")

        # ì¼ë°˜ ëŒ€í™”ì¸ ê²½ìš°
        if eval_id in SMALLTALK_IDS:
            print(f"\nğŸ—£ï¸  ì¼ë°˜ ëŒ€í™” (Smalltalk)")
            print(f"Query: {query}")
            print("\nìë™ìœ¼ë¡œ ground_truth = [] ì„¤ì •")

            annotated.append({
                'eval_id': eval_id,
                'query': query,
                'msg': item['msg'],
                'ground_truth': [],
                'confidence': 'certain',
                'difficulty': 'smalltalk'
            })
            continue

        # ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ
        results = search_and_display_detailed(es, query, eval_id, top_k=10)

        if not results:
            print("\nê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ - ê±´ë„ˆë›°ê¸°")
            continue

        # ì •ë‹µ ì…ë ¥
        print(f"\n{'='*80}")
        print(f"ì •ë‹µ ë¬¸ì„œ ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”:")
        print(f"  - 1~10: í•´ë‹¹ ë¬¸ì„œ ì„ íƒ (ì—¬ëŸ¬ ê°œëŠ” ì½¤ë§ˆë¡œ êµ¬ë¶„, ì˜ˆ: 1,2,3)")
        print(f"  - 0: ì¼ë°˜ ëŒ€í™”")
        print(f"  - s: ê±´ë„ˆë›°ê¸°")
        print(f"  - q: ì¢…ë£Œ")
        print(f"{'='*80}")

        answer = input("> ").strip().lower()

        if answer == 'q':
            print("\nì¢…ë£Œí•©ë‹ˆë‹¤...")
            break
        elif answer == 's':
            print("â­ï¸  ê±´ë„ˆëœ€")
            continue
        elif answer == '0':
            ground_truth = []
        else:
            try:
                indices = [int(x.strip())-1 for x in answer.split(',')]
                ground_truth = [results[i]['docid'] for i in indices
                              if 0 <= i < len(results)]
            except (ValueError, IndexError) as e:
                print(f"âš ï¸ ì…ë ¥ ì˜¤ë¥˜: {e}. ê±´ë„ˆëœ€")
                continue

        # ì‹ ë¢°ë„ ì…ë ¥
        print(f"\nì‹ ë¢°ë„ ë ˆë²¨ì„ ì…ë ¥í•˜ì„¸ìš”:")
        print(f"  1: Certain (í™•ì‹¤í•¨)")
        print(f"  2: Confident (ìì‹  ìˆìŒ)")
        print(f"  3: Uncertain (ì• ë§¤í•¨)")

        confidence_input = input("> ").strip()

        confidence_map = {
            '1': 'certain',
            '2': 'confident',
            '3': 'uncertain'
        }
        confidence = confidence_map.get(confidence_input, 'confident')

        # ë‚œì´ë„ ì •ë³´
        max_score = item.get('max_score', 0)
        if max_score >= 15:
            difficulty = 'easy'
        elif max_score >= 8:
            difficulty = 'medium'
        elif max_score >= 3:
            difficulty = 'hard'
        else:
            difficulty = 'very_hard'

        annotated.append({
            'eval_id': eval_id,
            'query': query,
            'msg': item['msg'],
            'ground_truth': ground_truth,
            'confidence': confidence,
            'difficulty': difficulty,
            'max_score': max_score
        })

        print(f"âœ… ì €ì¥: {len(ground_truth)}ê°œ ë¬¸ì„œ (ì‹ ë¢°ë„: {confidence})")

    return annotated

def save_validation_set(annotated, output_path):
    """Validation set ì €ì¥"""
    with open(output_path, 'w', encoding='utf-8') as f:
        for item in annotated:
            f.write(json.dumps(item, ensure_ascii=False) + '\n')

    # í†µê³„
    confidence_counts = defaultdict(int)
    difficulty_counts = defaultdict(int)

    for item in annotated:
        confidence_counts[item.get('confidence', 'unknown')] += 1
        difficulty_counts[item.get('difficulty', 'unknown')] += 1

    print(f"\n{'='*80}")
    print(f"âœ… Validation set ì €ì¥ ì™„ë£Œ: {output_path}")
    print(f"{'='*80}")
    print(f"\nì´ {len(annotated)}ê°œ ìƒ˜í”Œ ë ˆì´ë¸”ë§ ì™„ë£Œ")
    print(f"\nì‹ ë¢°ë„ë³„:")
    for conf, count in sorted(confidence_counts.items()):
        print(f"  {conf}: {count}ê°œ")
    print(f"\në‚œì´ë„ë³„:")
    for diff, count in sorted(difficulty_counts.items()):
        print(f"  {diff}: {count}ê°œ")
    print(f"{'='*80}")

def main():
    print("=" * 80)
    print("ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” Validation Set ìƒì„± ë„êµ¬")
    print("=" * 80)

    if not es.ping():
        print("âŒ Elasticsearch ì—°ê²° ì‹¤íŒ¨")
        return

    print("âœ… Elasticsearch ì—°ê²° ì„±ê³µ")

    # 1. ë‚œì´ë„ë³„ ë¶„ë¥˜
    categories = categorize_queries_by_difficulty()

    # 2. ê· í˜• ìƒ˜í”Œë§
    samples = stratified_sample(categories, total_samples=80)

    # 3. Annotation
    annotated = annotate_with_confidence(samples)

    # 4. ì €ì¥
    if annotated:
        save_validation_set(annotated, 'reliable_validation.jsonl')
    else:
        print("\nâš ï¸ ë ˆì´ë¸”ë§ëœ ì¿¼ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤")

if __name__ == "__main__":
    main()
