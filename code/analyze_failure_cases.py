"""
ì‹¤íŒ¨ ì¼€ì´ìŠ¤ ë¶„ì„ ë„êµ¬
- ì–´ë–¤ ì¿¼ë¦¬ì—ì„œ ì ìˆ˜ë¥¼ ìƒê³  ìˆëŠ”ì§€ ë¶„ì„
- Ground truthê°€ ì—†ìœ¼ë¯€ë¡œ submission ê°„ ë¹„êµ + ìˆ˜ë™ ê²€ì¦
"""

import json
from collections import defaultdict
from elasticsearch import Elasticsearch

def load_submission(path):
    """Submission íŒŒì¼ ë¡œë“œ"""
    with open(path, 'r') as f:
        return {json.loads(line)['eval_id']: json.loads(line) for line in f}

def load_eval():
    """Eval ë°ì´í„° ë¡œë“œ"""
    with open('../data/eval.jsonl', 'r') as f:
        return {json.loads(line)['eval_id']: json.loads(line) for line in f}

def analyze_low_confidence_queries(es):
    """
    ë‚®ì€ BM25 ì ìˆ˜ë¥¼ ë°›ì€ ì¿¼ë¦¬ ë¶„ì„
    - ì´ëŸ° ì¿¼ë¦¬ë“¤ì´ ì ìˆ˜ë¥¼ í¬ê²Œ ê¹ì•„ë¨¹ì„ ê°€ëŠ¥ì„±ì´ ë†’ìŒ
    """
    eval_data = load_eval()

    # ì¼ë°˜ ëŒ€í™” ì œì™¸
    smalltalk_ids = {276, 261, 233, 90, 222, 235, 165, 153, 169, 141, 183}

    low_score_queries = []

    for eval_id, item in eval_data.items():
        if eval_id in smalltalk_ids:
            continue

        # ì¿¼ë¦¬ ì¶”ì¶œ
        if isinstance(item['msg'], list):
            query = item['msg'][-1]['content']
        else:
            query = item['msg']

        # BM25 ê²€ìƒ‰
        response = es.search(
            index='test',
            body={
                'query': {
                    'match': {
                        'content': {
                            'query': query,
                            'analyzer': 'nori'
                        }
                    }
                },
                'size': 10
            }
        )

        if not response['hits']['hits']:
            max_score = 0
            top_docs = []
        else:
            max_score = response['hits']['hits'][0]['_score']
            top_docs = [hit['_source']['docid'] for hit in response['hits']['hits'][:5]]

        # ë‚®ì€ ì ìˆ˜ ì¼€ì´ìŠ¤
        if max_score < 10.0:
            low_score_queries.append({
                'eval_id': eval_id,
                'query': query,
                'max_score': max_score,
                'top_docs': top_docs,
                'msg': item['msg']
            })

    # ì ìˆ˜ ìˆœ ì •ë ¬
    low_score_queries.sort(key=lambda x: x['max_score'])

    return low_score_queries

def categorize_query_types(low_score_queries):
    """
    ì‹¤íŒ¨ ì¿¼ë¦¬ë¥¼ íƒ€ì…ë³„ë¡œ ë¶„ë¥˜
    """
    categories = {
        'context_dependent': [],  # ì´ì „ ëŒ€í™” ë§¥ë½ í•„ìš”
        'ambiguous': [],           # ëª¨í˜¸í•œ ì¿¼ë¦¬
        'specific_entity': [],     # íŠ¹ì • ê°œì²´ëª… í¬í•¨
        'abstract': [],            # ì¶”ìƒì  ê°œë…
        'other': []
    }

    for item in low_score_queries:
        query = item['query']
        msg = item['msg']

        # ì´ì „ ëŒ€í™” ë§¥ë½ì´ í•„ìš”í•œì§€ í™•ì¸
        if isinstance(msg, list) and len(msg) > 1:
            categories['context_dependent'].append(item)
        # "ê·¸ ì´ìœ ", "ê·¸ê²ƒ", "ì´ê²ƒ" ë“± ëŒ€ëª…ì‚¬ í¬í•¨
        elif any(word in query for word in ['ê·¸ ', 'ê·¸ê²ƒ', 'ì´ê²ƒ', 'ì´ê±°', 'ì €ê²ƒ', 'ì €ê±°']):
            categories['ambiguous'].append(item)
        # ê³ ìœ ëª…ì‚¬ í¬í•¨ (ëŒ€ë¬¸ìë¡œ ì‹œì‘í•˜ëŠ” ì˜ì–´ ë‹¨ì–´)
        elif any(word[0].isupper() for word in query.split() if word[0].isalpha()):
            categories['specific_entity'].append(item)
        # ì§§ì€ ì¿¼ë¦¬ (ì¶”ìƒì ì¼ ê°€ëŠ¥ì„±)
        elif len(query) < 15:
            categories['abstract'].append(item)
        else:
            categories['other'].append(item)

    return categories

def print_analysis(categories):
    """ë¶„ì„ ê²°ê³¼ ì¶œë ¥"""
    print(f"\n{'='*80}")
    print(f"ì‹¤íŒ¨ ì¼€ì´ìŠ¤ ë¶„ì„ ê²°ê³¼")
    print(f"{'='*80}\n")

    total = sum(len(items) for items in categories.values())
    print(f"ì´ ë‚®ì€ ì ìˆ˜ ì¿¼ë¦¬: {total}ê°œ\n")

    for cat_name, items in categories.items():
        if not items:
            continue

        print(f"\n{'='*80}")
        print(f"ğŸ“Š {cat_name.upper()} ({len(items)}ê°œ)")
        print(f"{'='*80}\n")

        for i, item in enumerate(items[:5], 1):  # ê° ì¹´í…Œê³ ë¦¬ ìƒìœ„ 5ê°œë§Œ
            print(f"[{i}] ID {item['eval_id']}: {item['query']}")
            print(f"    Max Score: {item['max_score']:.2f}")

            # ë©€í‹°í„´ ëŒ€í™”ì¸ ê²½ìš°
            if isinstance(item['msg'], list) and len(item['msg']) > 1:
                print(f"    ì´ì „ ëŒ€í™”:")
                for msg in item['msg'][:-1]:
                    role = "ğŸ‘¤" if msg['role'] == 'user' else "ğŸ¤–"
                    print(f"      {role} {msg['content'][:50]}...")

            print(f"    Top docs: {item['top_docs'][:2]}")
            print()

def suggest_solutions(categories):
    """í•´ê²°ì±… ì œì•ˆ"""
    print(f"\n{'='*80}")
    print(f"ğŸ’¡ í•´ê²°ì±… ì œì•ˆ")
    print(f"{'='*80}\n")

    solutions = []

    if categories['context_dependent']:
        solutions.append({
            'problem': f"Context-Dependent ì¿¼ë¦¬ ({len(categories['context_dependent'])}ê°œ)",
            'solution': "ë©€í‹°í„´ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ë¥¼ ì¿¼ë¦¬ì— í†µí•©",
            'priority': 'HIGH',
            'expected_gain': '+0.1~0.15'
        })

    if categories['ambiguous']:
        solutions.append({
            'problem': f"Ambiguous ì¿¼ë¦¬ ({len(categories['ambiguous'])}ê°œ)",
            'solution': "ëŒ€ëª…ì‚¬ë¥¼ êµ¬ì²´ì  ëª…ì‚¬ë¡œ ì¹˜í™˜ (Query Rewriting)",
            'priority': 'HIGH',
            'expected_gain': '+0.05~0.10'
        })

    if categories['specific_entity']:
        solutions.append({
            'problem': f"Specific Entity ì¿¼ë¦¬ ({len(categories['specific_entity'])}ê°œ)",
            'solution': "Entity ê¸°ë°˜ ê²€ìƒ‰ ê°•í™” (ì •í™•í•œ ë§¤ì¹­)",
            'priority': 'MEDIUM',
            'expected_gain': '+0.03~0.05'
        })

    if categories['abstract']:
        solutions.append({
            'problem': f"Abstract ì¿¼ë¦¬ ({len(categories['abstract'])}ê°œ)",
            'solution': "Query Expansion (ë™ì˜ì–´, ê´€ë ¨ í‚¤ì›Œë“œ)",
            'priority': 'MEDIUM',
            'expected_gain': '+0.02~0.05'
        })

    # ìš°ì„ ìˆœìœ„ ìˆœ ì •ë ¬
    priority_order = {'HIGH': 0, 'MEDIUM': 1, 'LOW': 2}
    solutions.sort(key=lambda x: priority_order[x['priority']])

    for i, sol in enumerate(solutions, 1):
        print(f"{i}. [{sol['priority']}] {sol['problem']}")
        print(f"   í•´ê²°ì±…: {sol['solution']}")
        print(f"   ì˜ˆìƒ ì ìˆ˜ í–¥ìƒ: {sol['expected_gain']}")
        print()

    # ì´ ì˜ˆìƒ í–¥ìƒ
    total_gain = sum(float(s['expected_gain'].split('~')[1]) for s in solutions)
    current_score = 0.63
    expected_score = current_score + total_gain

    print(f"\n{'='*80}")
    print(f"ğŸ“ˆ ì˜ˆìƒ ìµœì¢… ì ìˆ˜")
    print(f"{'='*80}")
    print(f"í˜„ì¬ ì ìˆ˜: {current_score}")
    print(f"ì˜ˆìƒ í–¥ìƒ: +{total_gain:.2f}")
    print(f"ì˜ˆìƒ ìµœì¢…: {expected_score:.2f}")

    if expected_score >= 0.9:
        print(f"âœ… ëª©í‘œ 0.9ì  ë‹¬ì„± ê°€ëŠ¥!")
    else:
        gap = 0.9 - expected_score
        print(f"âš ï¸  ëª©í‘œê¹Œì§€ {gap:.2f}ì  ì¶”ê°€ í•„ìš”")
        print(f"ğŸ’¡ ì¶”ê°€ ì „ëµ: Dense Retrieval, Hybrid Search ê³ ë„í™”")

def main():
    print("=" * 80)
    print("ì‹¤íŒ¨ ì¼€ì´ìŠ¤ ë¶„ì„ ë„êµ¬")
    print("=" * 80)

    # Elasticsearch ì—°ê²°
    es = Elasticsearch(['http://localhost:9200'])
    if not es.ping():
        print("âŒ Elasticsearch ì—°ê²° ì‹¤íŒ¨")
        return

    print("âœ… Elasticsearch ì—°ê²° ì„±ê³µ\n")

    # ë‚®ì€ ì ìˆ˜ ì¿¼ë¦¬ ë¶„ì„
    print("ğŸ” BM25 ë‚®ì€ ì ìˆ˜ ì¿¼ë¦¬ ë¶„ì„ ì¤‘...")
    low_score_queries = analyze_low_confidence_queries(es)

    print(f"âœ… ì´ {len(low_score_queries)}ê°œ ì¿¼ë¦¬ ë°œê²¬ (max_score < 10.0)\n")

    # ì¹´í…Œê³ ë¦¬ë³„ ë¶„ë¥˜
    categories = categorize_query_types(low_score_queries)

    # ê²°ê³¼ ì¶œë ¥
    print_analysis(categories)

    # í•´ê²°ì±… ì œì•ˆ
    suggest_solutions(categories)

    # ì €ì¥
    output_path = 'failure_analysis.json'
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump({
            'total_low_score': len(low_score_queries),
            'categories': {k: [{'eval_id': item['eval_id'],
                              'query': item['query'],
                              'max_score': item['max_score']}
                             for item in v]
                          for k, v in categories.items()},
            'queries': low_score_queries
        }, f, ensure_ascii=False, indent=2)

    print(f"\nâœ… ë¶„ì„ ê²°ê³¼ ì €ì¥: {output_path}")

if __name__ == "__main__":
    main()
