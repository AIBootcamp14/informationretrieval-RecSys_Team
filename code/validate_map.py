"""
ë¡œì»¬ MAP@3 ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸
Ground Truthë¥¼ ì‚¬ìš©í•˜ì—¬ ì œì¶œ íŒŒì¼ì˜ MAP ì ìˆ˜ë¥¼ ê³„ì‚°
"""

import json
import sys

def calculate_map_at_k(ground_truth_path, submission_path, k=3):
    """
    MAP@K ê³„ì‚°

    Args:
        ground_truth_path: Ground truth JSONL íŒŒì¼ ê²½ë¡œ
        submission_path: ì œì¶œ íŒŒì¼ ê²½ë¡œ (CSV í˜•ì‹)
        k: Top-K (ê¸°ë³¸ê°’: 3)

    Returns:
        MAP ì ìˆ˜
    """
    # Ground truth ë¡œë“œ
    ground_truth = {}
    with open(ground_truth_path, 'r', encoding='utf-8') as f:
        for line in f:
            item = json.loads(line)
            ground_truth[item['eval_id']] = set(item['ground_truth'])

    # ì œì¶œ íŒŒì¼ ë¡œë“œ
    submissions = {}
    with open(submission_path, 'r', encoding='utf-8') as f:
        for line in f:
            item = json.loads(line)
            submissions[item['eval_id']] = item['topk']

    # MAP ê³„ì‚°
    total_ap = 0.0
    num_queries = 0

    detailed_results = []

    for eval_id in sorted(ground_truth.keys()):
        gt_docs = ground_truth[eval_id]

        # Ground truthê°€ ë¹„ì–´ìˆìœ¼ë©´ ê±´ë„ˆë›°ê¸° (ì¼ë°˜ ëŒ€í™” ë˜ëŠ” ì •ë‹µ ì—†ìŒ)
        if not gt_docs:
            continue

        # ì œì¶œ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ AP=0
        if eval_id not in submissions:
            detailed_results.append({
                'eval_id': eval_id,
                'ap': 0.0,
                'retrieved': [],
                'ground_truth': list(gt_docs),
                'hits': 0
            })
            num_queries += 1
            continue

        retrieved_docs = submissions[eval_id][:k]

        # Average Precision ê³„ì‚°
        num_hits = 0
        sum_precisions = 0.0

        for i, doc_id in enumerate(retrieved_docs):
            if doc_id in gt_docs:
                num_hits += 1
                precision_at_i = num_hits / (i + 1)
                sum_precisions += precision_at_i

        # AP = (ê´€ë ¨ ë¬¸ì„œì—ì„œì˜ precisionë“¤ì˜ í•©) / (ê´€ë ¨ ë¬¸ì„œ ì´ ê°œìˆ˜)
        ap = sum_precisions / len(gt_docs) if gt_docs else 0.0

        detailed_results.append({
            'eval_id': eval_id,
            'ap': ap,
            'retrieved': retrieved_docs,
            'ground_truth': list(gt_docs),
            'hits': num_hits
        })

        total_ap += ap
        num_queries += 1

    # MAP = ëª¨ë“  ì¿¼ë¦¬ì˜ AP í‰ê· 
    map_score = total_ap / num_queries if num_queries > 0 else 0.0

    return map_score, detailed_results, num_queries

def print_results(map_score, detailed_results, num_queries, show_details=False):
    """ê²°ê³¼ ì¶œë ¥"""
    print("="*80)
    print("MAP@3 ê²€ì¦ ê²°ê³¼")
    print("="*80)
    print(f"ì´ ì¿¼ë¦¬ ìˆ˜:        {num_queries}ê°œ")
    print(f"MAP@3 ì ìˆ˜:        {map_score:.4f}")
    print("="*80)

    if show_details:
        print("\nìƒì„¸ ê²°ê³¼ (AP ë‚®ì€ ìˆœ):")
        print("-"*80)

        # AP ë‚®ì€ ìˆœìœ¼ë¡œ ì •ë ¬
        sorted_results = sorted(detailed_results, key=lambda x: x['ap'])

        for i, result in enumerate(sorted_results[:20], 1):
            print(f"\n{i}. eval_id={result['eval_id']}, AP={result['ap']:.3f}, Hits={result['hits']}/{len(result['ground_truth'])}")
            print(f"   Retrieved: {result['retrieved']}")
            print(f"   GT:        {result['ground_truth']}")

    # AP ë¶„í¬ í†µê³„
    ap_bins = {
        'AP=0.0': 0,
        '0.0<APâ‰¤0.3': 0,
        '0.3<APâ‰¤0.6': 0,
        '0.6<APâ‰¤0.9': 0,
        'AP>0.9': 0
    }

    for result in detailed_results:
        ap = result['ap']
        if ap == 0.0:
            ap_bins['AP=0.0'] += 1
        elif ap <= 0.3:
            ap_bins['0.0<APâ‰¤0.3'] += 1
        elif ap <= 0.6:
            ap_bins['0.3<APâ‰¤0.6'] += 1
        elif ap <= 0.9:
            ap_bins['0.6<APâ‰¤0.9'] += 1
        else:
            ap_bins['AP>0.9'] += 1

    print("\nğŸ“Š AP ë¶„í¬:")
    print("-"*80)
    for bin_name, count in ap_bins.items():
        pct = count / len(detailed_results) * 100 if detailed_results else 0
        print(f"   {bin_name:15s}: {count:3d}ê°œ ({pct:5.1f}%)")
    print("="*80)

def main():
    if len(sys.argv) < 2:
        print("ì‚¬ìš©ë²•: python validate_map.py <submission_file> [--details]")
        print("ì˜ˆì‹œ: python validate_map.py strategy_1_bm25_only_submission.csv --details")
        sys.exit(1)

    submission_path = sys.argv[1]
    show_details = '--details' in sys.argv

    ground_truth_path = 'ground_truth_solar_auto.jsonl'

    print(f"Ground Truth: {ground_truth_path}")
    print(f"Submission:   {submission_path}")
    print()

    try:
        map_score, detailed_results, num_queries = calculate_map_at_k(
            ground_truth_path,
            submission_path,
            k=3
        )

        print_results(map_score, detailed_results, num_queries, show_details)

        # ìƒì„¸ ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ì €ì¥
        if show_details:
            output_path = submission_path.replace('.csv', '_validation_details.json')
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump({
                    'map_score': map_score,
                    'num_queries': num_queries,
                    'detailed_results': detailed_results
                }, f, ensure_ascii=False, indent=2)
            print(f"\nğŸ’¾ ìƒì„¸ ê²°ê³¼ ì €ì¥: {output_path}")

    except FileNotFoundError as e:
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()
