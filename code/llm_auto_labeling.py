"""
LLM ê¸°ë°˜ ìë™ Ground Truth ìƒì„±
Solar-proê°€ ê³¼í•™ ì „ë¬¸ê°€ ì—­í• ë¡œ ì •ë‹µ ë¬¸ì„œ ì„ íƒ
"""

import json
import os
from tqdm import tqdm
from elasticsearch import Elasticsearch
from openai import OpenAI

# ES ì—°ê²°
es = Elasticsearch(['http://localhost:9200'])

# Solar API ì´ˆê¸°í™”
upstage_api_key = os.environ.get('UPSTAGE_API_KEY')
client = OpenAI(
    api_key=upstage_api_key,
    base_url="https://api.upstage.ai/v1/solar"
)

# ì¼ë°˜ ëŒ€í™” ID
SMALLTALK_IDS = {276, 261, 233, 90, 222, 235, 165, 153, 169, 141, 183}

def search_bm25(query, top_k=10):
    """BM25 ê²€ìƒ‰ìœ¼ë¡œ í›„ë³´ ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸°"""
    fetch_size = top_k + 2

    response = es.search(
        index='test',
        body={
            'query': {
                'match': {
                    'content': {
                        'query': query,
                        'analyzer': 'nori'
                    }
                }
            },
            'size': fetch_size
        }
    )

    if not response['hits']['hits']:
        return []

    # original_docid ê¸°ë°˜ ì¤‘ë³µ ì œê±°
    seen_original_docids = set()
    results = []

    for hit in response['hits']['hits']:
        source = hit['_source']
        original_docid = source.get('original_docid', source['docid'])

        if original_docid in seen_original_docids:
            continue

        seen_original_docids.add(original_docid)
        results.append({
            'docid': original_docid,
            'content': source['content'],
            'score': hit['_score']
        })

        if len(results) >= top_k:
            break

    return results

def llm_judge_relevance(query, documents):
    """
    LLMì´ ë¬¸ì„œë“¤ì„ í‰ê°€í•˜ì—¬ ì •ë‹µ ì„ íƒ
    """
    if not documents:
        return []

    # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    prompt = f"""ë‹¹ì‹ ì€ ê³¼í•™ ì§€ì‹ ê²€ìƒ‰ ì‹œìŠ¤í…œì˜ í‰ê°€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

**ì§ˆë¬¸**: {query}

ë‹¤ìŒì€ ê²€ìƒ‰ëœ ë¬¸ì„œ ëª©ë¡ì…ë‹ˆë‹¤. ì´ ì§ˆë¬¸ì— ë‹µí•˜ëŠ” ë° **ê°€ì¥ ì í•©í•œ ë¬¸ì„œ**ë¥¼ ì„ íƒí•˜ì„¸ìš”.

**ì„ íƒ ê¸°ì¤€**:
1. ì§ˆë¬¸ê³¼ ì§ì ‘ì ìœ¼ë¡œ ê´€ë ¨ëœ ë‚´ìš©ì„ í¬í•¨í•˜ëŠ”ê°€?
2. ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ì œê³µí•˜ëŠ”ê°€?
3. ê³¼í•™ì ìœ¼ë¡œ ì •í™•í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ”ê°€?

**ë¬¸ì„œ ëª©ë¡**:
"""

    for i, doc in enumerate(documents):
        # ë¬¸ì„œ ë‚´ìš© ìµœëŒ€ 400ìê¹Œì§€ë§Œ í‘œì‹œ
        content_preview = doc['content'][:400]
        if len(doc['content']) > 400:
            content_preview += "..."
        prompt += f"\n[{i}] {content_preview}\n"

    prompt += """
**ì¶œë ¥ í˜•ì‹**:
- ì •ë‹µì´ ë  ìˆ˜ ìˆëŠ” ë¬¸ì„œì˜ ë²ˆí˜¸ë¥¼ ì„ íƒí•˜ì„¸ìš” (ìµœëŒ€ 3ê°œ)
- ë²ˆí˜¸ë§Œ ì½¤ë§ˆë¡œ êµ¬ë¶„í•˜ì—¬ ì¶œë ¥í•˜ì„¸ìš” (ì˜ˆ: 0,2,5)
- ì í•©í•œ ë¬¸ì„œê°€ ì—†ìœ¼ë©´ "ì—†ìŒ"ì´ë¼ê³  ì¶œë ¥í•˜ì„¸ìš”
- ì„¤ëª…ì´ë‚˜ ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”

ì¶œë ¥:"""

    try:
        response = client.chat.completions.create(
            model="solar-pro",
            messages=[
                {
                    "role": "system",
                    "content": "ë‹¹ì‹ ì€ ê³¼í•™ ë¬¸ì„œ ê²€ìƒ‰ ì‹œìŠ¤í…œì˜ í‰ê°€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì •í™•í•˜ê³  ê°ê´€ì ìœ¼ë¡œ ë¬¸ì„œë¥¼ í‰ê°€í•©ë‹ˆë‹¤."
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            temperature=0.0,  # ì¼ê´€ì„± ì¤‘ìš”
            max_tokens=50
        )

        result = response.choices[0].message.content.strip()

        # "ì—†ìŒ" ë˜ëŠ” ë¹ˆ ì‘ë‹µ
        if not result or result == "ì—†ìŒ" or result.lower() == "none":
            return []

        # ìˆ«ì íŒŒì‹±
        selected_indices = []
        for part in result.split(','):
            part = part.strip()
            if part.isdigit():
                idx = int(part)
                if 0 <= idx < len(documents):
                    selected_indices.append(idx)

        # docid ë°˜í™˜
        return [documents[i]['docid'] for i in selected_indices[:3]]

    except Exception as e:
        print(f"âš ï¸  LLM íŒë‹¨ ì‹¤íŒ¨: {e}")
        return []

def build_ground_truth():
    """220ê°œ ì „ì²´ì— ëŒ€í•´ Ground Truth ìƒì„±"""
    print("="*80)
    print("LLM ê¸°ë°˜ ìë™ Ground Truth ìƒì„±")
    print("="*80)

    # ES ì—°ê²° í™•ì¸
    if not es.ping():
        print("âŒ Elasticsearch ì—°ê²° ì‹¤íŒ¨")
        return

    print("âœ… Elasticsearch ì—°ê²° ì„±ê³µ")

    # API Key í™•ì¸
    if not upstage_api_key:
        print("âŒ UPSTAGE_API_KEY í™˜ê²½ë³€ìˆ˜ ì—†ìŒ")
        return

    print("âœ… Solar API Key í™•ì¸\n")

    # eval.jsonl ë¡œë“œ
    with open('../data/eval.jsonl', 'r', encoding='utf-8') as f:
        eval_data = [json.loads(line) for line in f]

    print(f"ğŸ“‹ ì´ {len(eval_data)}ê°œ ì¿¼ë¦¬ ì²˜ë¦¬ ì‹œì‘\n")

    ground_truth = []
    stats = {'with_answers': 0, 'no_answers': 0, 'smalltalk': 0}

    for item in tqdm(eval_data, desc="LLM ë ˆì´ë¸”ë§"):
        eval_id = item['eval_id']

        # ì¿¼ë¦¬ ì¶”ì¶œ
        if isinstance(item['msg'], list):
            query = item['msg'][-1]['content']
        else:
            query = item['msg']

        # ì¼ë°˜ ëŒ€í™”ëŠ” ê±´ë„ˆë›°ê¸°
        if eval_id in SMALLTALK_IDS:
            ground_truth.append({
                'eval_id': eval_id,
                'query': query,
                'ground_truth': [],
                'type': 'smalltalk'
            })
            stats['smalltalk'] += 1
            continue

        # Top-10 ë¬¸ì„œ ê²€ìƒ‰
        docs = search_bm25(query, top_k=10)

        if not docs:
            ground_truth.append({
                'eval_id': eval_id,
                'query': query,
                'ground_truth': [],
                'type': 'no_docs_found'
            })
            stats['no_answers'] += 1
            continue

        # LLMìœ¼ë¡œ ì •ë‹µ ì„ íƒ
        selected_docids = llm_judge_relevance(query, docs)

        ground_truth.append({
            'eval_id': eval_id,
            'query': query,
            'ground_truth': selected_docids,
            'type': 'science',
            'num_candidates': len(docs)
        })

        if selected_docids:
            stats['with_answers'] += 1
        else:
            stats['no_answers'] += 1

        # ì¤‘ê°„ ì €ì¥ (50ê°œë§ˆë‹¤)
        if len(ground_truth) % 50 == 0:
            checkpoint_path = f'ground_truth_checkpoint_{len(ground_truth)}.jsonl'
            with open(checkpoint_path, 'w', encoding='utf-8') as f:
                for gt in ground_truth:
                    f.write(json.dumps(gt, ensure_ascii=False) + '\n')
            print(f"\nğŸ’¾ ì²´í¬í¬ì¸íŠ¸ ì €ì¥: {checkpoint_path}")

    # ìµœì¢… ì €ì¥
    output_path = 'ground_truth_solar_auto.jsonl'
    with open(output_path, 'w', encoding='utf-8') as f:
        for gt in ground_truth:
            f.write(json.dumps(gt, ensure_ascii=False) + '\n')

    print(f"\n{'='*80}")
    print(f"âœ… Ground Truth ìƒì„± ì™„ë£Œ")
    print(f"{'='*80}")
    print(f"ğŸ’¾ ì €ì¥ ìœ„ì¹˜: {output_path}")
    print(f"\nğŸ“Š í†µê³„:")
    print(f"   ì´ ì¿¼ë¦¬:       {len(ground_truth)}ê°œ")
    print(f"   ê³¼í•™ ì§ˆë¬¸:     {len(ground_truth) - stats['smalltalk']}ê°œ")
    print(f"   - ì •ë‹µ ìˆìŒ:   {stats['with_answers']}ê°œ ({stats['with_answers']/(len(ground_truth)-stats['smalltalk'])*100:.1f}%)")
    print(f"   - ì •ë‹µ ì—†ìŒ:   {stats['no_answers']}ê°œ")
    print(f"   ì¼ë°˜ ëŒ€í™”:     {stats['smalltalk']}ê°œ")
    print(f"{'='*80}")

if __name__ == "__main__":
    build_ground_truth()
