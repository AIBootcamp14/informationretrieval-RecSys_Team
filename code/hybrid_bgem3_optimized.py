"""
BGE-M3 ìµœì í™” Hybrid Search ì†”ë£¨ì…˜
ì„¸ ê°€ì§€ ê²€ìƒ‰ ëª¨ë“œ í™œìš©: Dense + Sparse + ColBERT
ëª©í‘œ: 0.79+ MAP@3 ë‹¬ì„±
"""

import json
import os
import pickle
import numpy as np
from tqdm import tqdm
from elasticsearch import Elasticsearch
from FlagEmbedding import BGEM3FlagModel
from openai import OpenAI

# ES ì—°ê²°
es = Elasticsearch(['http://localhost:9200'])

# Solar API ì´ˆê¸°í™”
upstage_api_key = os.environ.get('UPSTAGE_API_KEY')
client = None
if upstage_api_key:
    client = OpenAI(
        api_key=upstage_api_key,
        base_url="https://api.upstage.ai/v1/solar"
    )

# BGE-M3 ëª¨ë¸ ë¡œë“œ
print("BGE-M3 ëª¨ë¸ ë¡œë“œ ì¤‘...")
model = BGEM3FlagModel('BAAI/bge-m3', use_fp16=True)
print("âœ… BGE-M3 ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")

# ì¼ë°˜ ëŒ€í™” ID
SMALLTALK_IDS = {276, 261, 233, 90, 222, 235, 165, 153, 169, 141, 183}

# BGE-M3 ìµœì í™” ì„ë² ë”© ë¡œë“œ
print("\nBGE-M3 ìµœì í™” ì„ë² ë”© ë¡œë“œ ì¤‘...")
with open('embeddings_test_bgem3_optimized.pkl', 'rb') as f:
    embeddings_dict = pickle.load(f)
print(f"âœ… {len(embeddings_dict)}ê°œ ë¬¸ì„œ ì„ë² ë”© ë¡œë“œ ì™„ë£Œ")

# ìƒ˜í”Œ ì„ë² ë”© êµ¬ì¡° í™•ì¸
sample_docid = list(embeddings_dict.keys())[0]
sample_emb = embeddings_dict[sample_docid]
print(f"   Dense ì°¨ì›: {len(sample_emb['dense'])}")
print(f"   Sparse í† í° ìˆ˜: {len(sample_emb['sparse'])}")
print(f"   ColBERT ë²¡í„° ìˆ˜: {sample_emb['colbert'].shape[0]}")

def search_bm25(query, top_k=20):
    """BM25 ê²€ìƒ‰"""
    fetch_size = top_k + 5

    response = es.search(
        index='test',
        body={
            'query': {
                'match': {
                    'content': {
                        'query': query,
                        'analyzer': 'nori'
                    }
                }
            },
            'size': fetch_size
        }
    )

    if not response['hits']['hits']:
        return []

    # original_docid ê¸°ë°˜ ì¤‘ë³µ ì œê±°
    seen_original_docids = set()
    results = []

    for hit in response['hits']['hits']:
        source = hit['_source']
        original_docid = source.get('original_docid', source['docid'])

        if original_docid in seen_original_docids:
            continue

        seen_original_docids.add(original_docid)
        results.append({
            'docid': original_docid,
            'content': source['content'],
            'score': hit['_score'],
            'source': 'bm25'
        })

        if len(results) >= top_k:
            break

    return results

def bgem3_hybrid_score(query_dense, query_sparse, query_colbert,
                       doc_dense, doc_sparse, doc_colbert,
                       w1=0.4, w2=0.3, w3=0.3):
    """
    BGE-M3 Hybrid Scoring

    Args:
        query_dense: ì¿¼ë¦¬ dense ë²¡í„° (1024,)
        query_sparse: ì¿¼ë¦¬ sparse ê°€ì¤‘ì¹˜ dict {token_id: weight}
        query_colbert: ì¿¼ë¦¬ ColBERT ë²¡í„° (M, 1024)
        doc_dense: ë¬¸ì„œ dense ë²¡í„° (1024,)
        doc_sparse: ë¬¸ì„œ sparse ê°€ì¤‘ì¹˜ dict {token_id: weight}
        doc_colbert: ë¬¸ì„œ ColBERT ë²¡í„° (N, 1024)
        w1, w2, w3: ê°€ì¤‘ì¹˜ (í•©=1.0)

    Returns:
        hybrid_score: ìµœì¢… ìŠ¤ì½”ì–´
    """
    # 1. Dense ìœ ì‚¬ë„ (ì½”ì‚¬ì¸)
    s_dense = np.dot(query_dense, doc_dense) / (
        np.linalg.norm(query_dense) * np.linalg.norm(doc_dense)
    )

    # 2. Sparse ìœ ì‚¬ë„ (ê³µí†µ í† í° ê°€ì¤‘ì¹˜ ê³±ì˜ í•©)
    s_lex = 0.0
    if query_sparse and doc_sparse:
        common_tokens = set(query_sparse.keys()) & set(doc_sparse.keys())
        for token in common_tokens:
            s_lex += query_sparse[token] * doc_sparse[token]

    # 3. ColBERT ìœ ì‚¬ë„ (MaxSim)
    # MaxSim: ê° ì¿¼ë¦¬ ë²¡í„°ì— ëŒ€í•´ ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì„œ ë²¡í„°ì˜ í‰ê· 
    s_mul = 0.0
    if query_colbert.shape[0] > 0 and doc_colbert.shape[0] > 0:
        # ì •ê·œí™”
        query_colbert_norm = query_colbert / np.linalg.norm(query_colbert, axis=1, keepdims=True)
        doc_colbert_norm = doc_colbert / np.linalg.norm(doc_colbert, axis=1, keepdims=True)

        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ í–‰ë ¬ (M x N)
        sim_matrix = np.dot(query_colbert_norm, doc_colbert_norm.T)

        # MaxSim: ê° ì¿¼ë¦¬ ë²¡í„°ì˜ ìµœëŒ€ ìœ ì‚¬ë„ í‰ê· 
        s_mul = np.mean(np.max(sim_matrix, axis=1))

    # Hybrid Score
    hybrid_score = w1 * s_dense + w2 * s_lex + w3 * s_mul

    return hybrid_score

def search_bgem3_hybrid(query, embeddings_dict, top_k=20,
                        w1=0.4, w2=0.3, w3=0.3):
    """
    BGE-M3 Hybrid Search (Dense + Sparse + ColBERT)

    Args:
        query: ê²€ìƒ‰ ì¿¼ë¦¬
        embeddings_dict: BGE-M3 ìµœì í™” ì„ë² ë”© ë”•ì…”ë„ˆë¦¬
        top_k: ë°˜í™˜í•  ë¬¸ì„œ ìˆ˜
        w1, w2, w3: Dense, Sparse, ColBERT ê°€ì¤‘ì¹˜
    """
    # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„± (ì„¸ ê°€ì§€ ëª¨ë‘)
    query_embedding = model.encode(
        [query],
        return_dense=True,
        return_sparse=True,
        return_colbert_vecs=True,
        max_length=64  # ì¿¼ë¦¬ëŠ” ì§§ê²Œ
    )

    query_dense = query_embedding['dense_vecs'][0]
    query_sparse = query_embedding['lexical_weights'][0]
    query_colbert = query_embedding['colbert_vecs'][0]

    # ëª¨ë“  ë¬¸ì„œì— ëŒ€í•´ Hybrid Score ê³„ì‚°
    scores = []
    for docid, doc_emb in embeddings_dict.items():
        try:
            hybrid_score = bgem3_hybrid_score(
                query_dense, query_sparse, query_colbert,
                doc_emb['dense'], doc_emb['sparse'], doc_emb['colbert'],
                w1, w2, w3
            )
            scores.append((docid, hybrid_score))
        except Exception as e:
            # ì„ë² ë”© ì˜¤ë¥˜ ì‹œ ìŠ¤í‚µ
            continue

    # ì •ë ¬
    scores.sort(key=lambda x: x[1], reverse=True)

    # ESì—ì„œ content ê°€ì ¸ì˜¤ê¸°
    results = []
    for docid, score in scores[:top_k]:
        try:
            resp = es.search(
                index='test',
                body={
                    'query': {
                        'bool': {
                            'should': [
                                {'term': {'docid.keyword': docid}},
                                {'term': {'original_docid.keyword': docid}}
                            ]
                        }
                    },
                    'size': 1
                }
            )

            if resp['hits']['hits']:
                source = resp['hits']['hits'][0]['_source']
                results.append({
                    'docid': docid,
                    'content': source['content'],
                    'score': float(score),
                    'source': 'bgem3_hybrid'
                })
        except Exception as e:
            continue

    return results

def hybrid_search_rrf_bgem3(query, embeddings_dict, top_k=20, k=60,
                            w1=0.4, w2=0.3, w3=0.3):
    """
    RRF Fusion: BM25 + BGE-M3 Hybrid

    Args:
        query: ê²€ìƒ‰ ì¿¼ë¦¬
        embeddings_dict: BGE-M3 ìµœì í™” ì„ë² ë”©
        top_k: ê° ê²€ìƒ‰ì—ì„œ ê°€ì ¸ì˜¬ ë¬¸ì„œ ìˆ˜
        k: RRF íŒŒë¼ë¯¸í„°
        w1, w2, w3: BGE-M3 ê°€ì¤‘ì¹˜
    """
    # BM25 ê²€ìƒ‰
    bm25_results = search_bm25(query, top_k=top_k)

    # BGE-M3 Hybrid ê²€ìƒ‰
    bgem3_results = search_bgem3_hybrid(query, embeddings_dict, top_k=top_k,
                                        w1=w1, w2=w2, w3=w3)

    # RRF ìŠ¤ì½”ì–´ ê³„ì‚°
    rrf_scores = {}
    doc_contents = {}

    # BM25 ê²°ê³¼
    for rank, doc in enumerate(bm25_results, 1):
        docid = doc['docid']
        rrf_scores[docid] = rrf_scores.get(docid, 0) + 1 / (k + rank)
        doc_contents[docid] = doc['content']

    # BGE-M3 Hybrid ê²°ê³¼
    for rank, doc in enumerate(bgem3_results, 1):
        docid = doc['docid']
        rrf_scores[docid] = rrf_scores.get(docid, 0) + 1 / (k + rank)
        doc_contents[docid] = doc['content']

    # ìŠ¤ì½”ì–´ ìˆœìœ¼ë¡œ ì •ë ¬
    sorted_docs = sorted(rrf_scores.items(), key=lambda x: x[1], reverse=True)

    # ê²°ê³¼ ìƒì„±
    results = []
    for docid, score in sorted_docs:
        results.append({
            'docid': docid,
            'content': doc_contents[docid],
            'score': score
        })

    return results

def llm_rerank(query, docs, top_k=3):
    """Solar-proë¡œ Reranking"""
    if not docs or len(docs) <= top_k or not client:
        return [doc['docid'] for doc in docs[:top_k]]

    try:
        # ë¬¸ì„œ ëª©ë¡ ìƒì„±
        doc_list = []
        for i, doc in enumerate(docs[:15]):  # ìƒìœ„ 15ê°œë§Œ í‰ê°€
            content_preview = doc['content'][:300]
            if len(doc['content']) > 300:
                content_preview += "..."
            doc_list.append(f"[{i}] {content_preview}")

        docs_text = "\n\n".join(doc_list)

        response = client.chat.completions.create(
            model="solar-pro",
            messages=[
                {
                    "role": "system",
                    "content": "ë‹¹ì‹ ì€ ê³¼í•™ ì§€ì‹ ê²€ìƒ‰ ì‹œìŠ¤í…œì˜ relevance íŒë‹¨ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì¿¼ë¦¬ì— ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ë¬¸ì„œë¥¼ ì •í™•íˆ ì„ íƒí•˜ì„¸ìš”."
                },
                {
                    "role": "user",
                    "content": f"""ì¿¼ë¦¬: {query}

ë¬¸ì„œë“¤:
{docs_text}

ì´ ì§ˆë¬¸ì— ë‹µí•˜ëŠ” ë° ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ë¬¸ì„œ {top_k}ê°œì˜ ë²ˆí˜¸ë¥¼ ì„ íƒí•˜ì„¸ìš”.
- ì§ˆë¬¸ê³¼ ì§ì ‘ ê´€ë ¨ëœ ë‚´ìš©ì„ í¬í•¨í•˜ëŠ”ê°€?
- ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ì œê³µí•˜ëŠ”ê°€?
- ê³¼í•™ì ìœ¼ë¡œ ì •í™•í•œê°€?

ì¶œë ¥: ë²ˆí˜¸ë§Œ ì½¤ë§ˆë¡œ êµ¬ë¶„ (ì˜ˆ: 0,2,4)
ì„¤ëª… ì—†ì´ ë²ˆí˜¸ë§Œ ì¶œë ¥í•˜ì„¸ìš”."""
                }
            ],
            temperature=0.0,
            max_tokens=30
        )

        result = response.choices[0].message.content.strip()
        indices = [int(x.strip()) for x in result.split(',') if x.strip().isdigit()]

        reranked_docids = []
        for idx in indices[:top_k]:
            if 0 <= idx < len(docs):
                reranked_docids.append(docs[idx]['docid'])

        # ë¶€ì¡±í•˜ë©´ ì›ë˜ ìˆœì„œë¡œ ì±„ìš°ê¸°
        for doc in docs:
            if len(reranked_docids) >= top_k:
                break
            if doc['docid'] not in reranked_docids:
                reranked_docids.append(doc['docid'])

        return reranked_docids[:top_k]

    except Exception as e:
        print(f"âš ï¸  Reranking ì‹¤íŒ¨: {e}")
        return [doc['docid'] for doc in docs[:top_k]]

def optimized_bgem3_strategy(eval_id, query, embeddings_dict,
                             w1=0.4, w2=0.3, w3=0.3):
    """
    BGE-M3 ìµœì í™” ì „ëµ

    Pipeline:
    1. BM25 + BGE-M3 Hybrid (Dense+Sparse+ColBERT) â†’ RRF Fusion
    2. LLM Reranking

    Args:
        eval_id: í‰ê°€ ID
        query: ê²€ìƒ‰ ì¿¼ë¦¬
        embeddings_dict: BGE-M3 ìµœì í™” ì„ë² ë”©
        w1, w2, w3: BGE-M3 ê°€ì¤‘ì¹˜
    """
    # ì¼ë°˜ ëŒ€í™”ëŠ” ë¹ˆ ê²°ê³¼
    if eval_id in SMALLTALK_IDS:
        return []

    # Hybrid Search (RRF)
    hybrid_results = hybrid_search_rrf_bgem3(
        query, embeddings_dict,
        top_k=20, k=60,
        w1=w1, w2=w2, w3=w3
    )

    if not hybrid_results:
        return []

    # LLM Reranking
    final_topk = llm_rerank(query, hybrid_results, top_k=3)

    return final_topk

def run_optimized_experiment(w1=0.4, w2=0.3, w3=0.3, exp_name="default"):
    """
    BGE-M3 ìµœì í™” ì‹¤í—˜ ì‹¤í–‰

    Args:
        w1, w2, w3: BGE-M3 ê°€ì¤‘ì¹˜ (Dense, Sparse, ColBERT)
        exp_name: ì‹¤í—˜ ì´ë¦„
    """
    print("="*80)
    print(f"BGE-M3 ìµœì í™” Hybrid Search ì‹¤í—˜: {exp_name}")
    print("="*80)
    print(f"ì „ëµ: BM25 + BGE-M3 Hybrid (Dense+Sparse+ColBERT) + RRF + LLM")
    print(f"ê°€ì¤‘ì¹˜: Dense={w1:.1f}, Sparse={w2:.1f}, ColBERT={w3:.1f}")
    print("="*80)

    # Eval ë°ì´í„° ë¡œë“œ
    with open('../data/eval.jsonl', 'r', encoding='utf-8') as f:
        eval_data = [json.loads(line) for line in f]

    print(f"\nğŸ“‹ ì´ {len(eval_data)}ê°œ ì¿¼ë¦¬ ì²˜ë¦¬ ì‹œì‘\n")

    results = []

    for item in tqdm(eval_data, desc=f"BGE-M3 ìµœì í™” ({exp_name})"):
        eval_id = item['eval_id']

        # ì¿¼ë¦¬ ì¶”ì¶œ
        if isinstance(item['msg'], list):
            query = item['msg'][-1]['content']
        else:
            query = item['msg']

        # ìµœì í™” ì „ëµ ì‹¤í–‰
        topk = optimized_bgem3_strategy(eval_id, query, embeddings_dict,
                                        w1=w1, w2=w2, w3=w3)

        results.append({
            'eval_id': eval_id,
            'retrieve': topk
        })

    # ì œì¶œ íŒŒì¼ ìƒì„±
    output_path = f'hybrid_bgem3_optimized_{exp_name}_submission.csv'
    with open(output_path, 'w', encoding='utf-8') as f:
        for r in results:
            json_obj = {
                'eval_id': r['eval_id'],
                'topk': r['retrieve']
            }
            f.write(json.dumps(json_obj, ensure_ascii=False) + '\n')

    print(f"\n{'='*80}")
    print(f"âœ… ì‹¤í—˜ ì™„ë£Œ")
    print(f"{'='*80}")
    print(f"ğŸ’¾ ì œì¶œ íŒŒì¼: {output_path}")
    print(f"{'='*80}")

    return results

if __name__ == "__main__":
    # Phase 1: ê¸°ë³¸ ê°€ì¤‘ì¹˜ë¡œ í…ŒìŠ¤íŠ¸
    print("\nğŸš€ Phase 1: ê¸°ë³¸ ê°€ì¤‘ì¹˜ (0.4, 0.3, 0.3)")
    run_optimized_experiment(w1=0.4, w2=0.3, w3=0.3, exp_name="w433")

    print("\n" + "="*80)
    print("âœ… BGE-M3 ìµœì í™” ì‹¤í—˜ ì™„ë£Œ!")
    print("="*80)
    print("\në‹¤ìŒ ë‹¨ê³„:")
    print("1. ê²°ê³¼ í™•ì¸ í›„ ê°€ì¤‘ì¹˜ íŠœë‹ (Phase 2)")
    print("2. ìµœì  ê°€ì¤‘ì¹˜ ì¡°í•© íƒìƒ‰")
    print("   - ì˜ˆ: w1=0.3, w2=0.3, w3=0.4 (ColBERT ê°•ì¡°)")
    print("   - ì˜ˆ: w1=0.5, w2=0.2, w3=0.3 (Dense ê°•ì¡°)")
