"""
High-Impact Query Validation Tool
validation_candidates.jsonì—ì„œ ì‹ë³„ëœ ìƒìœ„ 20ê°œ ì¿¼ë¦¬ì— ëŒ€í•´ ìˆ˜ë™ ë ˆì´ë¸”ë§
"""

import json
from elasticsearch import Elasticsearch

def load_high_impact_queries():
    """validation_candidates.jsonì—ì„œ high-impact ì¿¼ë¦¬ ë¡œë“œ"""
    with open('validation_candidates.json', 'r') as f:
        candidates = json.load(f)

    # eval.jsonlì—ì„œ ì „ì²´ ì •ë³´ ë¡œë“œ
    with open('../data/eval.jsonl', 'r') as f:
        eval_data = {json.loads(line)['eval_id']: json.loads(line)
                     for line in f}

    # Candidateì— ì „ì²´ ì •ë³´ ì¶”ê°€
    for candidate in candidates:
        eval_id = candidate['eval_id']
        if eval_id in eval_data:
            candidate['msg'] = eval_data[eval_id]['msg']

    return candidates

def search_and_display(es, query, top_k=10):
    """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë³´ì—¬ì£¼ê³  ì •ë‹µ ì„ íƒ"""
    response = es.search(
        index='test',
        body={
            'query': {
                'match': {
                    'content': {
                        'query': query,
                        'analyzer': 'nori'
                    }
                }
            },
            'size': top_k
        }
    )

    print(f"\n{'='*80}")
    print(f"Query: {query}")
    print(f"{'='*80}")

    results = []
    for i, hit in enumerate(response['hits']['hits'], 1):
        docid = hit['_source']['docid']
        score = hit['_score']
        content = hit['_source']['content'][:300]

        print(f"\n[{i}] Score: {score:.2f}")
        print(f"DocID: {docid}")
        print(f"Content: {content}...")

        results.append({
            'docid': docid,
            'score': score,
            'content': hit['_source']['content']
        })

    return results

def show_submission_comparison(candidate):
    """ê° submissionì˜ TopK ë¹„êµ í‘œì‹œ"""
    print(f"\n{'='*80}")
    print(f"ê¸°ì¡´ Submissionë“¤ì˜ ë‹µë³€:")
    print(f"{'='*80}")

    for name, topk in candidate.get('topks', {}).items():
        print(f"\n{name}: {len(topk)}ê°œ ë¬¸ì„œ")
        for i, docid in enumerate(topk[:3], 1):
            print(f"  [{i}] {docid}")

def annotate_high_impact_queries(candidates, es):
    """High-impact ì¿¼ë¦¬ì— ì •ë‹µ ë ˆì´ë¸” ì¶”ê°€"""
    annotated = []

    print(f"\n{'#'*80}")
    print(f"ì´ {len(candidates)}ê°œì˜ High-Impact ì¿¼ë¦¬ì— ëŒ€í•´ ë ˆì´ë¸”ë§ì„ ì§„í–‰í•©ë‹ˆë‹¤")
    print(f"{'#'*80}")

    for idx, candidate in enumerate(candidates, 1):
        eval_id = candidate['eval_id']
        query = candidate['query']
        variation = candidate.get('variation', 0)

        print(f"\n\n{'#'*80}")
        print(f"[{idx}/{len(candidates)}] Eval ID: {eval_id}")
        print(f"Variation: {variation}ê°€ì§€ (ë†’ì„ìˆ˜ë¡ submissionê°„ ì°¨ì´ê°€ í¼)")
        print(f"{'#'*80}")

        # ê¸°ì¡´ submission ë¹„êµ
        show_submission_comparison(candidate)

        # ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ
        results = search_and_display(es, query, top_k=10)

        # ì •ë‹µ ì…ë ¥
        print(f"\n{'='*80}")
        print(f"ì •ë‹µ ë¬¸ì„œ ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”:")
        print(f"  - 1-10: í•´ë‹¹ ë¬¸ì„œ ì„ íƒ (ì—¬ëŸ¬ ê°œëŠ” ì½¤ë§ˆë¡œ êµ¬ë¶„, ì˜ˆ: 1,2,3)")
        print(f"  - 0: ì¼ë°˜ ëŒ€í™” (ë¬¸ì„œ ì—†ìŒ)")
        print(f"  - s: ê±´ë„ˆë›°ê¸°")
        print(f"{'='*80}")
        answer = input("> ").strip()

        if answer.lower() == 's':
            print("â­ï¸  ê±´ë„ˆëœ€")
            continue

        if answer == "0":
            ground_truth = []
        else:
            try:
                indices = [int(x.strip())-1 for x in answer.split(',')]
                ground_truth = [results[i]['docid'] for i in indices
                              if 0 <= i < len(results)]
            except (ValueError, IndexError) as e:
                print(f"âš ï¸ ì…ë ¥ ì˜¤ë¥˜: {e}. ê±´ë„ˆëœ€")
                continue

        annotated.append({
            'eval_id': eval_id,
            'query': query,
            'msg': candidate.get('msg', query),
            'ground_truth': ground_truth,
            'variation': variation,
            'confidence': 'manual'
        })

        print(f"âœ… ì €ì¥: {len(ground_truth)}ê°œ ë¬¸ì„œ")

    return annotated

def save_validation_set(annotated, output_path):
    """validation set ì €ì¥"""
    with open(output_path, 'w', encoding='utf-8') as f:
        for item in annotated:
            f.write(json.dumps(item, ensure_ascii=False) + '\n')

    print(f"\n{'='*80}")
    print(f"âœ… Validation set ì €ì¥ ì™„ë£Œ: {output_path}")
    print(f"ì´ {len(annotated)}ê°œ ìƒ˜í”Œ ë ˆì´ë¸”ë§ ì™„ë£Œ")
    print(f"{'='*80}")

def main():
    print("=" * 80)
    print("High-Impact Query Validation Tool")
    print("=" * 80)

    # Elasticsearch ì—°ê²°
    es = Elasticsearch(['http://localhost:9200'])
    if not es.ping():
        print("âŒ Elasticsearch ì—°ê²° ì‹¤íŒ¨")
        return

    print("âœ… Elasticsearch ì—°ê²° ì„±ê³µ\n")

    # High-impact ì¿¼ë¦¬ ë¡œë“œ
    candidates = load_high_impact_queries()
    print(f"ğŸ“‹ {len(candidates)}ê°œ High-Impact ì¿¼ë¦¬ ë¡œë“œë¨")
    print(f"ğŸ’¡ ì´ ì¿¼ë¦¬ë“¤ì€ ì—¬ëŸ¬ submissionì—ì„œ ê²°ê³¼ê°€ ê°€ì¥ ë§ì´ ë‹¤ë¥¸ ì¿¼ë¦¬ë“¤ì…ë‹ˆë‹¤")

    # Annotation
    annotated = annotate_high_impact_queries(candidates, es)

    # ì €ì¥
    if annotated:
        save_validation_set(annotated, 'validation_high_impact.jsonl')
    else:
        print("\nâš ï¸ ë ˆì´ë¸”ë§ëœ ì¿¼ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤")

if __name__ == "__main__":
    main()
