"""
Ultra High-Quality Validation Set Creation using Solar Pro
5ë‹¨ê³„ ê²€ì¦ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ìµœê³  í’ˆì§ˆì˜ ë°¸ë¦¬ë°ì´ì…˜ ì„¸íŠ¸ ìƒì„±

ëª©í‘œ: 120~150ê°œ ultra-high-quality validation samples
ì‹ ë¢°ë„: 95%+
"""

import json
import os
import pickle
from collections import Counter
from tqdm import tqdm
from elasticsearch import Elasticsearch
from FlagEmbedding import BGEM3FlagModel
from openai import OpenAI
import numpy as np

# ES ì—°ê²°
es = Elasticsearch(['http://localhost:9200'])

# Solar API ì´ˆê¸°í™”
upstage_api_key = os.environ.get('UPSTAGE_API_KEY')
if not upstage_api_key:
    raise ValueError("UPSTAGE_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

client = OpenAI(
    api_key=upstage_api_key,
    base_url="https://api.upstage.ai/v1/solar"
)

# BGE-M3 ëª¨ë¸ ë¡œë“œ
print("BGE-M3 ëª¨ë¸ ë¡œë“œ ì¤‘...")
model = BGEM3FlagModel('BAAI/bge-m3', use_fp16=True)
print("âœ… BGE-M3 ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")

# ì¼ë°˜ ëŒ€í™” ID
SMALLTALK_IDS = {276, 261, 233, 90, 222, 235, 165, 153, 169, 141, 183}

# BGE-M3 ìµœì í™” ì„ë² ë”© ë¡œë“œ
print("\nBGE-M3 ìµœì í™” ì„ë² ë”© ë¡œë“œ ì¤‘...")
with open('embeddings_test_bgem3_optimized.pkl', 'rb') as f:
    embeddings_dict = pickle.load(f)
print(f"âœ… {len(embeddings_dict)}ê°œ ë¬¸ì„œ ì„ë² ë”© ë¡œë“œ ì™„ë£Œ")


def rewrite_query_with_context(msg):
    """ë©€í‹°í„´ ëŒ€í™”ì˜ ë§¥ë½ì„ í†µí•©í•˜ì—¬ ì¿¼ë¦¬ ì¬ì‘ì„±"""
    if isinstance(msg, str):
        return msg

    if len(msg) == 1:
        return msg[0]['content']

    current_query = msg[-1]['content']

    # ëŒ€ëª…ì‚¬ë‚˜ ëª¨í˜¸í•œ í‘œí˜„ í™•ì¸
    ambiguous_terms = ['ê·¸ ', 'ê·¸ê²ƒ', 'ì´ê²ƒ', 'ì´ê±°', 'ì €ê²ƒ', 'ì €ê±°', 'ì™œ', 'ì–´ë–»ê²Œ', 'ì´ìœ ']

    if not any(term in current_query for term in ambiguous_terms):
        return current_query

    # LLMìœ¼ë¡œ ì¿¼ë¦¬ ì¬ì‘ì„±
    conversation_context = "\n".join([
        f"{m['role']}: {m['content']}" for m in msg[:-1]
    ])

    prompt = f"""ë‹¤ìŒì€ ì´ì „ ëŒ€í™” ë‚´ìš©ì…ë‹ˆë‹¤:

{conversation_context}

í˜„ì¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:
"{current_query}"

ì´ ì§ˆë¬¸ì„ ì´ì „ ëŒ€í™”ì˜ ë§¥ë½ì„ ë°˜ì˜í•˜ì—¬ ë…ë¦½ì ìœ¼ë¡œ ì´í•´ ê°€ëŠ¥í•œ ì™„ì „í•œ ì§ˆë¬¸ìœ¼ë¡œ ì¬ì‘ì„±í•´ì£¼ì„¸ìš”.
ëŒ€ëª…ì‚¬(ê·¸ê²ƒ, ì´ê²ƒ ë“±)ë¥¼ êµ¬ì²´ì ì¸ ëª…ì‚¬ë¡œ ë°”ê¿”ì£¼ì„¸ìš”.

ì¬ì‘ì„±ëœ ì§ˆë¬¸ë§Œ ì¶œë ¥í•˜ì„¸ìš”. ë‹¤ë¥¸ ì„¤ëª…ì€ í•˜ì§€ ë§ˆì„¸ìš”."""

    try:
        response = client.chat.completions.create(
            model="solar-pro",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.1,
            max_tokens=150
        )

        rewritten = response.choices[0].message.content.strip()
        rewritten = rewritten.strip('"').strip("'")

        return rewritten

    except Exception as e:
        return current_query


def search_bm25(query, top_k=20):
    """BM25 ê²€ìƒ‰"""
    fetch_size = top_k + 5

    response = es.search(
        index='test',
        body={
            'query': {
                'match': {
                    'content': {
                        'query': query,
                        'analyzer': 'nori'
                    }
                }
            },
            'size': fetch_size
        }
    )

    if not response['hits']['hits']:
        return []

    # original_docid ê¸°ë°˜ ì¤‘ë³µ ì œê±°
    seen_original_docids = set()
    results = []

    for hit in response['hits']['hits']:
        source = hit['_source']
        original_docid = source.get('original_docid', source['docid'])

        if original_docid in seen_original_docids:
            continue

        seen_original_docids.add(original_docid)
        results.append({
            'docid': original_docid,
            'content': source['content'],
            'score': hit['_score'],
            'source': 'bm25'
        })

        if len(results) >= top_k:
            break

    return results


def bgem3_hybrid_score(query_dense, query_sparse, query_colbert,
                       doc_dense, doc_sparse, doc_colbert,
                       w1=0.4, w2=0.3, w3=0.3):
    """BGE-M3 Hybrid Scoring"""
    # 1. Dense ìœ ì‚¬ë„
    s_dense = np.dot(query_dense, doc_dense) / (
        np.linalg.norm(query_dense) * np.linalg.norm(doc_dense)
    )

    # 2. Sparse ìœ ì‚¬ë„
    s_lex = 0.0
    if query_sparse and doc_sparse:
        common_tokens = set(query_sparse.keys()) & set(doc_sparse.keys())
        for token in common_tokens:
            s_lex += query_sparse[token] * doc_sparse[token]

    # 3. ColBERT ìœ ì‚¬ë„
    s_mul = 0.0
    if query_colbert.shape[0] > 0 and doc_colbert.shape[0] > 0:
        query_colbert_norm = query_colbert / np.linalg.norm(query_colbert, axis=1, keepdims=True)
        doc_colbert_norm = doc_colbert / np.linalg.norm(doc_colbert, axis=1, keepdims=True)
        sim_matrix = np.dot(query_colbert_norm, doc_colbert_norm.T)
        s_mul = np.mean(np.max(sim_matrix, axis=1))

    hybrid_score = w1 * s_dense + w2 * s_lex + w3 * s_mul
    return hybrid_score


def search_bgem3_hybrid(query, embeddings_dict, top_k=20, max_length=128):
    """BGE-M3 Hybrid ê²€ìƒ‰"""
    # BGE-M3 ì¿¼ë¦¬ ì„ë² ë”©
    query_embedding = model.encode(
        [query],
        return_dense=True,
        return_sparse=True,
        return_colbert_vecs=True,
        max_length=max_length
    )

    query_dense = query_embedding['dense_vecs'][0]
    query_sparse = query_embedding['lexical_weights'][0]
    query_colbert = query_embedding['colbert_vecs'][0]

    # ëª¨ë“  ë¬¸ì„œì— ëŒ€í•´ Hybrid Score ê³„ì‚°
    scores = []
    for docid, doc_emb in embeddings_dict.items():
        score = bgem3_hybrid_score(
            query_dense, query_sparse, query_colbert,
            doc_emb['dense'], doc_emb['sparse'], doc_emb['colbert']
        )
        scores.append((docid, score))

    # ì •ë ¬
    scores.sort(key=lambda x: x[1], reverse=True)

    # ESì—ì„œ content ê°€ì ¸ì˜¤ê¸°
    results = []
    for docid, score in scores[:top_k]:
        try:
            resp = es.search(
                index='test',
                body={
                    'query': {
                        'bool': {
                            'should': [
                                {'term': {'docid.keyword': docid}},
                                {'term': {'original_docid.keyword': docid}}
                            ]
                        }
                    },
                    'size': 1
                }
            )

            if resp['hits']['hits']:
                source = resp['hits']['hits'][0]['_source']
                results.append({
                    'docid': docid,
                    'content': source['content'],
                    'score': float(score),
                    'source': 'bgem3_hybrid'
                })
        except Exception as e:
            continue

    return results


def hybrid_search_rrf(query, embeddings_dict, top_k=20, k=60, query_max_length=128):
    """RRFë¡œ BM25 + BGE-M3 Hybrid ê²°í•©"""
    # BM25 ê²€ìƒ‰
    bm25_results = search_bm25(query, top_k=top_k)

    # BGE-M3 Hybrid ê²€ìƒ‰
    bgem3_results = search_bgem3_hybrid(query, embeddings_dict, top_k=top_k, max_length=query_max_length)

    # RRF ìŠ¤ì½”ì–´ ê³„ì‚°
    rrf_scores = {}
    doc_contents = {}

    for rank, doc in enumerate(bm25_results, 1):
        docid = doc['docid']
        rrf_scores[docid] = rrf_scores.get(docid, 0) + 1 / (k + rank)
        doc_contents[docid] = doc['content']

    for rank, doc in enumerate(bgem3_results, 1):
        docid = doc['docid']
        rrf_scores[docid] = rrf_scores.get(docid, 0) + 1 / (k + rank)
        doc_contents[docid] = doc['content']

    # ì •ë ¬
    sorted_docs = sorted(rrf_scores.items(), key=lambda x: x[1], reverse=True)

    results = []
    for docid, score in sorted_docs:
        results.append({
            'docid': docid,
            'content': doc_contents[docid],
            'score': score
        })

    return results


# ========== Phase 1: Multi-Pass Self-Consistency ==========

def solar_label_docs(query, docs, temperature=0.0, top_k=5):
    """Solar Proë¡œ ë¬¸ì„œ ë¼ë²¨ë§ (ë‹¨ì¼ í˜¸ì¶œ)"""
    if not docs:
        return []

    try:
        # ë¬¸ì„œ ëª©ë¡ ì‘ì„±
        doc_list = []
        for i, doc in enumerate(docs[:20]):  # Top 20ë§Œ í‰ê°€
            content_preview = doc['content'][:250]
            if len(doc['content']) > 250:
                content_preview += "..."
            doc_list.append(f"[{i}] {content_preview}")

        docs_text = "\n\n".join(doc_list)

        response = client.chat.completions.create(
            model="solar-pro",
            messages=[
                {
                    "role": "system",
                    "content": "ë‹¹ì‹ ì€ ê³¼í•™ ì§€ì‹ ê²€ìƒ‰ ì‹œìŠ¤í…œì˜ ì •ë‹µ ë¼ë²¨ë§ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."
                },
                {
                    "role": "user",
                    "content": f"""ì¿¼ë¦¬: {query}

ë¬¸ì„œë“¤:
{docs_text}

ì´ ì§ˆë¬¸ì— ë‹µí•˜ê¸° ìœ„í•´ ê°€ì¥ ê´€ë ¨ì„±ì´ ë†’ì€ ë¬¸ì„œ {top_k}ê°œì˜ ë²ˆí˜¸ë¥¼ ì„ íƒí•˜ì„¸ìš”.
ê´€ë ¨ì„±ì´ ë†’ì€ ìˆœì„œëŒ€ë¡œ ë‚˜ì—´í•˜ì„¸ìš”.

ì¶œë ¥: ë²ˆí˜¸ë§Œ ì½¤ë§ˆë¡œ êµ¬ë¶„ (ì˜ˆ: 0,2,4,5,7)
ì„¤ëª… ì—†ì´ ë²ˆí˜¸ë§Œ ì¶œë ¥í•˜ì„¸ìš”."""
                }
            ],
            temperature=temperature,
            max_tokens=50
        )

        # íŒŒì‹±
        result_text = response.choices[0].message.content.strip()

        # ë²ˆí˜¸ ì¶”ì¶œ
        import re
        numbers = re.findall(r'\d+', result_text)
        selected_indices = [int(n) for n in numbers if int(n) < len(docs)][:top_k]

        return selected_indices

    except Exception as e:
        print(f"  âš ï¸ Solar labeling ì‹¤íŒ¨: {e}")
        return list(range(min(top_k, len(docs))))


def phase1_multipass_consensus(query, docs):
    """
    Phase 1: Multi-Pass Self-Consistency
    3ë²ˆ í˜¸ì¶œí•˜ì—¬ 2/3 í•©ì˜ëœ ë¬¸ì„œë§Œ ì„ íƒ
    """
    if not docs or len(docs) < 3:
        return [doc['docid'] for doc in docs]

    # 3ë²ˆ í˜¸ì¶œ (temp 0.0, 0.3, 0.0)
    temperatures = [0.0, 0.3, 0.0]
    all_selections = []

    for temp in temperatures:
        indices = solar_label_docs(query, docs, temperature=temp, top_k=5)
        selected_docids = [docs[i]['docid'] for i in indices if i < len(docs)]
        all_selections.append(selected_docids)

    # 2/3 ì´ìƒ ì„ íƒëœ ë¬¸ì„œë§Œ ì¶”ì¶œ
    docid_counts = Counter()
    for selection in all_selections:
        for docid in selection:
            docid_counts[docid] += 1

    # 2ë²ˆ ì´ìƒ ì„ íƒëœ ë¬¸ì„œ
    consensus_docs = [docid for docid, count in docid_counts.items() if count >= 2]

    return consensus_docs


# ========== Phase 2: Detailed Scoring with Rationale ==========

def phase2_detailed_scoring(query, docs, candidate_docids):
    """
    Phase 2: ìƒì„¸ ì ìˆ˜í™” ë° ê·¼ê±° ìƒì„±
    ê° ë¬¸ì„œì— ëŒ€í•´ 1-5ì  í‰ê°€ + ê·¼ê±°
    """
    if not candidate_docids:
        return []

    # candidate_docidsì— í•´ë‹¹í•˜ëŠ” ë¬¸ì„œë§Œ ì¶”ì¶œ
    candidate_docs = [doc for doc in docs if doc['docid'] in candidate_docids]

    detailed_scores = []

    for doc in candidate_docids[:10]:  # ìµœëŒ€ 10ê°œê¹Œì§€ë§Œ ìƒì„¸ í‰ê°€
        # í•´ë‹¹ docidì˜ content ì°¾ê¸°
        doc_content = None
        for d in docs:
            if d['docid'] == doc:
                doc_content = d['content']
                break

        if not doc_content:
            continue

        content_preview = doc_content[:500]
        if len(doc_content) > 500:
            content_preview += "..."

        try:
            response = client.chat.completions.create(
                model="solar-pro",
                messages=[
                    {
                        "role": "system",
                        "content": "ë‹¹ì‹ ì€ ì—„ê²©í•œ ë¬¸ì„œ í‰ê°€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."
                    },
                    {
                        "role": "user",
                        "content": f"""ì¿¼ë¦¬: {query}

ë¬¸ì„œ:
{content_preview}

ì´ ë¬¸ì„œê°€ ì¿¼ë¦¬ì— ë‹µí•˜ëŠ” ì •ë„ë¥¼ 1-5ì ìœ¼ë¡œ í‰ê°€í•˜ì„¸ìš”.

í‰ê°€ ê¸°ì¤€:
5ì : ì¿¼ë¦¬ì— ì§ì ‘ì ì´ê³  ì™„ì „í•œ ë‹µë³€ í¬í•¨
4ì : ê´€ë ¨ì„± ë†’ìœ¼ë‚˜ ì¼ë¶€ ì •ë³´ ë¶€ì¡±
3ì : ê´€ë ¨ì€ ìˆìœ¼ë‚˜ ë¶ˆì¶©ë¶„
2ì : ì•½ê°„ ê´€ë ¨
1ì : ë¬´ê´€

ì¶œë ¥ í˜•ì‹:
ì ìˆ˜: X
ê·¼ê±°: [êµ¬ì²´ì  ì´ìœ  1-2ë¬¸ì¥]
ì¦ê±°: [ë¬¸ì„œì˜ ê´€ë ¨ ë¶€ë¶„ ì¸ìš© 1ë¬¸ì¥]

ìœ„ í˜•ì‹ëŒ€ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”."""
                    }
                ],
                temperature=0.0,
                max_tokens=300
            )

            result_text = response.choices[0].message.content.strip()

            # ì ìˆ˜ ì¶”ì¶œ
            import re
            score_match = re.search(r'ì ìˆ˜:\s*(\d)', result_text)
            if not score_match:
                continue

            score = int(score_match.group(1))

            # ê·¼ê±°ì™€ ì¦ê±° ì¶”ì¶œ
            rationale_match = re.search(r'ê·¼ê±°:\s*(.+?)(?=ì¦ê±°:|$)', result_text, re.DOTALL)
            evidence_match = re.search(r'ì¦ê±°:\s*(.+?)$', result_text, re.DOTALL)

            rationale = rationale_match.group(1).strip() if rationale_match else "N/A"
            evidence = evidence_match.group(1).strip() if evidence_match else "N/A"

            # 3ì  ì´ìƒë§Œ ì±„íƒ (í™•ì¥ëœ validation set ìƒì„±ì„ ìœ„í•´ ì„ê³„ê°’ ë‚®ì¶¤)
            if score >= 3:
                detailed_scores.append({
                    'docid': doc,
                    'score': score,
                    'rationale': rationale,
                    'evidence': evidence
                })

        except Exception as e:
            print(f"  âš ï¸ Detailed scoring ì‹¤íŒ¨ for {doc}: {e}")
            continue

    return detailed_scores


# ========== Phase 3: Confidence-Based Filtering ==========

def phase3_confidence_check(query, detailed_scores):
    """
    Phase 3: ì „ì²´ ì •ë‹µ ì„¸íŠ¸ì— ëŒ€í•œ ì‹ ë¢°ë„ í‰ê°€
    1-5ì , 4ì  ì´ìƒë§Œ í†µê³¼
    """
    if not detailed_scores:
        return None

    # ìƒìœ„ 3ê°œ ë¬¸ì„œ ì •ë³´
    top3_docs = detailed_scores[:3]
    doc_summary = "\n".join([
        f"ë¬¸ì„œ {i+1}: {doc['rationale'][:100]}"
        for i, doc in enumerate(top3_docs)
    ])

    try:
        response = client.chat.completions.create(
            model="solar-pro",
            messages=[
                {
                    "role": "system",
                    "content": "ë‹¹ì‹ ì€ ì •ë‹µ ì„¸íŠ¸ ì‹ ë¢°ë„ í‰ê°€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."
                },
                {
                    "role": "user",
                    "content": f"""ì¿¼ë¦¬: {query}

ì •ë‹µ í›„ë³´ ë¬¸ì„œë“¤:
{doc_summary}

ì´ ì •ë‹µ ì„¸íŠ¸ê°€ ì¿¼ë¦¬ì— ëŒ€í•œ ì˜¬ë°”ë¥¸ ë‹µë³€ì¸ì§€ ì‹ ë¢°ë„ë¥¼ í‰ê°€í•˜ì„¸ìš”.

ì‹ ë¢°ë„ ì²™ë„:
5ì  (Certain): 100% í™•ì‹ , ëª…í™•í•œ ì •ë‹µ
4ì  (High): 90% í™•ì‹ , ë†’ì€ ê´€ë ¨ì„±
3ì  (Medium): 70% í™•ì‹ , ì–´ëŠ ì •ë„ ê´€ë ¨
2ì  (Low): 50% í™•ì‹ , ë¶ˆí™•ì‹¤
1ì  (Uncertain): í™•ì‹  ì—†ìŒ

ì¶œë ¥ í˜•ì‹:
ì‹ ë¢°ë„: X
ì´ìœ : [1-2ë¬¸ì¥]

ìœ„ í˜•ì‹ëŒ€ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”."""
                }
            ],
            temperature=0.0,
            max_tokens=200
        )

        result_text = response.choices[0].message.content.strip()

        # ì‹ ë¢°ë„ ì ìˆ˜ ì¶”ì¶œ
        import re
        conf_match = re.search(r'ì‹ ë¢°ë„:\s*(\d)', result_text)
        if not conf_match:
            return None

        confidence_score = int(conf_match.group(1))

        # ì´ìœ  ì¶”ì¶œ
        reason_match = re.search(r'ì´ìœ :\s*(.+?)$', result_text, re.DOTALL)
        reason = reason_match.group(1).strip() if reason_match else "N/A"

        return {
            'score': confidence_score,
            'reason': reason
        }

    except Exception as e:
        print(f"  âš ï¸ Confidence check ì‹¤íŒ¨: {e}")
        return None


# ========== Phase 4: Multi-Turn Query Enhancement ==========

def phase4_multiturn_rewrites(msg):
    """
    Phase 4: ë©€í‹°í„´ ì¿¼ë¦¬ 3ê°€ì§€ ì¬ì‘ì„± ë²„ì „ ìƒì„±
    """
    if isinstance(msg, str) or len(msg) == 1:
        return None  # ë‹¨ì¼í„´ì€ ìŠ¤í‚µ

    current_query = msg[-1]['content']

    # ëŒ€ëª…ì‚¬ê°€ ì—†ìœ¼ë©´ ìŠ¤í‚µ
    ambiguous_terms = ['ê·¸ ', 'ê·¸ê²ƒ', 'ì´ê²ƒ', 'ì´ê±°', 'ì €ê²ƒ', 'ì €ê±°', 'ì™œ', 'ì–´ë–»ê²Œ', 'ì´ìœ ']
    if not any(term in current_query for term in ambiguous_terms):
        return None

    conversation_context = "\n".join([
        f"{m['role']}: {m['content']}" for m in msg[:-1]
    ])

    try:
        response = client.chat.completions.create(
            model="solar-pro",
            messages=[
                {
                    "role": "system",
                    "content": "ë‹¹ì‹ ì€ ì¿¼ë¦¬ ì¬ì‘ì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤."
                },
                {
                    "role": "user",
                    "content": f"""ë‹¤ìŒì€ ì´ì „ ëŒ€í™” ë‚´ìš©ì…ë‹ˆë‹¤:

{conversation_context}

í˜„ì¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸:
"{current_query}"

ì´ ì§ˆë¬¸ì„ ì´ì „ ëŒ€í™” ë§¥ë½ì„ ë°˜ì˜í•˜ì—¬ 3ê°€ì§€ ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ì¬ì‘ì„±í•´ì£¼ì„¸ìš”.
ê° ì¬ì‘ì„±ì€ ë…ë¦½ì ìœ¼ë¡œ ì´í•´ ê°€ëŠ¥í•´ì•¼ í•˜ë©°, ëŒ€ëª…ì‚¬ë¥¼ êµ¬ì²´ì  ëª…ì‚¬ë¡œ ë°”ê¿”ì•¼ í•©ë‹ˆë‹¤.

ì¶œë ¥ í˜•ì‹:
1. [ì²« ë²ˆì§¸ ì¬ì‘ì„±]
2. [ë‘ ë²ˆì§¸ ì¬ì‘ì„±]
3. [ì„¸ ë²ˆì§¸ ì¬ì‘ì„±]

ìœ„ í˜•ì‹ëŒ€ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”."""
                }
            ],
            temperature=0.5,  # ë‹¤ì–‘ì„±ì„ ìœ„í•´ temperature ì¦ê°€
            max_tokens=300
        )

        result_text = response.choices[0].message.content.strip()

        # ì¬ì‘ì„± ì¶”ì¶œ
        import re
        rewrites = re.findall(r'\d+\.\s*(.+?)(?=\d+\.|$)', result_text, re.DOTALL)
        rewrites = [r.strip() for r in rewrites if r.strip()]

        return rewrites[:3] if len(rewrites) >= 3 else None

    except Exception as e:
        print(f"  âš ï¸ Multi-turn rewrites ì‹¤íŒ¨: {e}")
        return None


# ========== Phase 5: Adversarial Self-Validation ==========

def phase5_adversarial_validation(query, detailed_scores):
    """
    Phase 5: Solar Proê°€ ìì‹ ì˜ ì •ë‹µì„ ë¹„íŒì ìœ¼ë¡œ ì¬ê²€ì¦
    """
    if not detailed_scores:
        return "FAIL"

    # ì •ë‹µ ë¬¸ì„œ ìš”ì•½
    answer_summary = "\n".join([
        f"ë¬¸ì„œ {i+1}: {doc['rationale'][:150]}"
        for i, doc in enumerate(detailed_scores[:3])
    ])

    try:
        response = client.chat.completions.create(
            model="solar-pro",
            messages=[
                {
                    "role": "system",
                    "content": "ë‹¹ì‹ ì€ ì—„ê²©í•œ í’ˆì§ˆ ê²€ì¦ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì •ë‹µ í›„ë³´ë¥¼ ë¹„íŒì ìœ¼ë¡œ í‰ê°€í•˜ì„¸ìš”."
                },
                {
                    "role": "user",
                    "content": f"""ì¿¼ë¦¬: {query}

ì •ë‹µ í›„ë³´:
{answer_summary}

ì´ ì •ë‹µ í›„ë³´ê°€ ì •ë§ ì˜¬ë°”ë¥¸ì§€ ë¹„íŒì ìœ¼ë¡œ ê²€í† í•˜ì„¸ìš”.

ê°€ëŠ¥í•œ ë¬¸ì œì :
- ì¿¼ë¦¬ì™€ ì‹¤ì œë¡œ ë¬´ê´€í•œê°€?
- ì¼ë¶€ë§Œ ë‹µí•˜ê³  í•µì‹¬ì„ ë†“ì³¤ëŠ”ê°€?
- ì˜¤í•´ì˜ ì†Œì§€ê°€ ìˆëŠ”ê°€?
- ë„ˆë¬´ ì¼ë°˜ì ì´ê±°ë‚˜ ëª¨í˜¸í•œê°€?

ë¬¸ì œê°€ ì—†ìœ¼ë©´ "PASS", ë¬¸ì œê°€ ìˆìœ¼ë©´ "FAIL"ì„ ì¶œë ¥í•˜ê³  ì´ìœ ë¥¼ 1-2ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”.

ì¶œë ¥ í˜•ì‹:
íŒì •: PASS ë˜ëŠ” FAIL
ì´ìœ : [ì´ìœ ]

ìœ„ í˜•ì‹ëŒ€ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”."""
                }
            ],
            temperature=0.0,
            max_tokens=300
        )

        result_text = response.choices[0].message.content.strip()

        # PASS/FAIL ì¶”ì¶œ
        if "PASS" in result_text:
            return "PASS"
        else:
            return "FAIL"

    except Exception as e:
        print(f"  âš ï¸ Adversarial validation ì‹¤íŒ¨: {e}")
        return "FAIL"


# ========== ë©”ì¸ íŒŒì´í”„ë¼ì¸ ==========

def create_ultra_validation_set(eval_path, output_path):
    """Ultra ê³ í’ˆì§ˆ ë°¸ë¦¬ë°ì´ì…˜ ì„¸íŠ¸ ìƒì„±"""
    # ë°ì´í„° ë¡œë“œ
    with open(eval_path, 'r') as f:
        eval_data = [json.loads(line) for line in f]

    validation_set = []
    rejected_set = []

    stats = {
        'total': 0,
        'smalltalk_skipped': 0,
        'phase1_failed': 0,
        'phase2_failed': 0,
        'phase3_failed': 0,
        'phase5_failed': 0,
        'passed': 0
    }

    print(f"\n{'='*80}")
    print(f"Ultra High-Quality Validation Set Creation")
    print(f"{'='*80}\n")

    for item in tqdm(eval_data, desc="Processing queries"):
        stats['total'] += 1
        eval_id = item['eval_id']
        msg = item['msg']

        # ì¼ë°˜ ëŒ€í™” ìŠ¤í‚µ
        if eval_id in SMALLTALK_IDS:
            stats['smalltalk_skipped'] += 1
            continue

        # ì¿¼ë¦¬ ì¬ì‘ì„±
        query = rewrite_query_with_context(msg)

        # ë¬¸ì„œ ê²€ìƒ‰ (Top 20)
        docs = hybrid_search_rrf(query, embeddings_dict, top_k=20)

        if len(docs) < 3:
            stats['phase1_failed'] += 1
            rejected_set.append({
                'eval_id': eval_id,
                'query': query,
                'reason': 'insufficient_docs',
                'phase': 'initial_search'
            })
            continue

        # Phase 1: Multi-Pass Consensus
        consensus_docids = phase1_multipass_consensus(query, docs)

        if len(consensus_docids) < 3:
            stats['phase1_failed'] += 1
            rejected_set.append({
                'eval_id': eval_id,
                'query': query,
                'reason': 'no_consensus',
                'phase': 'phase1',
                'consensus_count': len(consensus_docids)
            })
            continue

        # Phase 2: Detailed Scoring
        detailed_scores = phase2_detailed_scoring(query, docs, consensus_docids)

        if len(detailed_scores) < 3:
            stats['phase2_failed'] += 1
            rejected_set.append({
                'eval_id': eval_id,
                'query': query,
                'reason': 'low_scores',
                'phase': 'phase2',
                'scored_count': len(detailed_scores)
            })
            continue

        # Phase 3: Confidence Check
        confidence = phase3_confidence_check(query, detailed_scores)

        if not confidence or confidence['score'] < 4:
            stats['phase3_failed'] += 1
            rejected_set.append({
                'eval_id': eval_id,
                'query': query,
                'reason': 'low_confidence',
                'phase': 'phase3',
                'confidence': confidence['score'] if confidence else 0
            })
            continue

        # Phase 4: Multi-Turn Rewrites (optional, ê²€ì¦ìš©)
        rewrites = None
        if isinstance(msg, list) and len(msg) > 1:
            rewrites = phase4_multiturn_rewrites(msg)

        # Phase 5: Adversarial Validation
        validation_result = phase5_adversarial_validation(query, detailed_scores)

        if validation_result != "PASS":
            stats['phase5_failed'] += 1
            rejected_set.append({
                'eval_id': eval_id,
                'query': query,
                'reason': 'failed_adversarial',
                'phase': 'phase5'
            })
            continue

        # ìµœì¢… ìŠ¹ì¸!
        stats['passed'] += 1

        # ì ìˆ˜ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ìƒìœ„ 3ê°œë¥¼ ground truthë¡œ ì„ íƒ
        sorted_scores = sorted(detailed_scores, key=lambda x: x['score'], reverse=True)

        validation_entry = {
            'eval_id': eval_id,
            'query': query if isinstance(msg, str) else msg,
            'rewritten_query': query,
            'ground_truth': [s['docid'] for s in sorted_scores[:3]],
            'detailed_scores': detailed_scores,
            'confidence': confidence,
            'rewrites': rewrites,
            'validation': 'PASS',
            'quality': 'ultra_high'
        }

        validation_set.append(validation_entry)

    # ê²°ê³¼ ì €ì¥
    with open(output_path, 'w', encoding='utf-8') as f:
        for entry in validation_set:
            f.write(json.dumps(entry, ensure_ascii=False) + '\n')

    with open('validation_rejected.jsonl', 'w', encoding='utf-8') as f:
        for entry in rejected_set:
            f.write(json.dumps(entry, ensure_ascii=False) + '\n')

    # í†µê³„ ì €ì¥
    with open('validation_stats.json', 'w', encoding='utf-8') as f:
        json.dump(stats, f, indent=2, ensure_ascii=False)

    # í†µê³„ ì¶œë ¥
    print(f"\n{'='*80}")
    print(f"âœ… Ultra Validation Set ìƒì„± ì™„ë£Œ")
    print(f"{'='*80}")
    print(f"\nğŸ“Š í†µê³„:")
    print(f"  ì „ì²´ ì¿¼ë¦¬: {stats['total']}")
    print(f"  ì¼ë°˜ ëŒ€í™” ì œì™¸: {stats['smalltalk_skipped']}")
    print(f"  Phase 1 ì‹¤íŒ¨ (í•©ì˜ ë¶€ì¡±): {stats['phase1_failed']}")
    print(f"  Phase 2 ì‹¤íŒ¨ (ë‚®ì€ ì ìˆ˜): {stats['phase2_failed']}")
    print(f"  Phase 3 ì‹¤íŒ¨ (ë‚®ì€ ì‹ ë¢°ë„): {stats['phase3_failed']}")
    print(f"  Phase 5 ì‹¤íŒ¨ (ê²€ì¦ ì‹¤íŒ¨): {stats['phase5_failed']}")
    print(f"  âœ… ìµœì¢… í†µê³¼: {stats['passed']} samples")
    print(f"\n  ì‹ ë¢°ë„: {stats['passed']/(stats['total']-stats['smalltalk_skipped'])*100:.1f}%")
    print(f"{'='*80}")

    return validation_set, rejected_set, stats


def main():
    print("="*80)
    print("Ultra High-Quality Validation Set Creation")
    print("Solar Pro 5-Phase Pipeline")
    print("="*80)

    # Elasticsearch ì—°ê²° í™•ì¸
    if not es.ping():
        print("âŒ Elasticsearch ì—°ê²° ì‹¤íŒ¨")
        return

    print("âœ… Elasticsearch ì—°ê²° ì„±ê³µ")

    # ì²˜ë¦¬
    validation_set, rejected_set, stats = create_ultra_validation_set(
        eval_path='../data/eval.jsonl',
        output_path='ultra_validation_solar.jsonl'
    )

    print(f"\nğŸ’¾ ì €ì¥ ì™„ë£Œ:")
    print(f"  - ultra_validation_solar.jsonl: {len(validation_set)}ê°œ")
    print(f"  - validation_rejected.jsonl: {len(rejected_set)}ê°œ")
    print(f"  - validation_stats.json")


if __name__ == "__main__":
    main()
