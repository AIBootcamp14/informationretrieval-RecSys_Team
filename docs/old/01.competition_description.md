# 대회 소개

LLM의 등장 이후 여러 산업 분야에서 지식을 다루는 업무들이 점점
고도화되고 있습니다.

특히 정보를 찾기 위해 검색엔진의 입력창에 키워드를 입력하고 결과를
확인하고 원하는 정보가 없으면 다른 키워드로 다시 검색하기를 반복하는
번거로운 과정을 이제 더이상 자주 할 필요가 없어졌습니다.

이제 LLM한테 물어보면 질문의 의도까지 파악해서 필요한 내용만 잘 정리해서
알려 줍니다.

그렇지만 LLM이 가진 근본적인 한계도 있습니다.

먼저, 정보라는 것은 의미나 가치가 시간에 따라 계속 변하기 때문에 모델이
이를 실시간으로 학습하기 힘들고 이 때문에 아래 예시처럼 knowledge cutoff
가 자연스럽게 발생합니다.

그리고 LLM이 알려주는 지식이 항상 사실에 기반한 것이 아닌 경우가 종종
있습니다. 특히 특정 도메인이나 문제 영역은 매우 심각한 거짓 정보들을
생성해 내곤 합니다.

이러한 환각 현상은 메타인지를 학습하지 않은 LLM의 근본적인 한계라 볼 수
있습니다.

모델은 학습 과정에서 정보를 압축해서 저장하기 때문에 정보의 손실이
발생할 수밖에 없고, 이 때문에 특정 입력 조건에 대해서는 사실 여부보다는
지식의 국소적인 패턴이 더 큰 영향을 주면서 답변이 생성될 수 있기
때문입니다.

이러한 문제를 극복하기 위해서는 RAG(Retrieval Augmented Generation)
기술이 필수입니다.

RAG는 질문에 적합한 레퍼런스 추출을 위해 검색엔진을 활용하고 답변 생성을
위해 LLM(Large Language Model)을 활용합니다.

이때 LLM은 스스로 알고 있는 지식을 출력하기보다는 언어 추론 능력을
극대화하는 것에 방점을 둡니다.

이렇게 사실에 기반한 지식 정보를 토대로 질문에 답을 하고 출처 정보도
같이 줄 수 있기 때문에 사용자는 훨씬 더 안심하고 정보를 소비할 수 있게
됩니다.

이번 대회에서는 과학 상식을 질문하는 시나리오를 가정하고 과학 상식 문서
4200여개를 미리 검색엔진에 색인해 둡니다.

대화 메시지 또는 질문이 들어오면 과학 상식에 대한 질문 의도인지 그렇지
않은지 판단 후에 과학 상식 질문이라면 검색엔진으로부터 적합한 문서들을
추출하고 이를 기반으로 답변을 생성합니다.

만일 과학 상식 이외의 질문이라면 검색엔진을 활용할 필요 없이 적절한 답을
바로 생성합니다.

마지막으로, 본 프로젝트는 모델링에 중점을 둔 대회가 아니라 RAG(Retrieval
Augmented Generation) 시스템의 개발에 집중하고 있습니다. 이 대회는 여러
모델과 다양한 기법, 그리고 앙상블을 활용하여 모델의 성능을 향상시키는
일반적인 모델링 대회와는 다릅니다. 대신에 검색 엔진이 올바른 문서를
색인했는지, 그리고 생성된 답변이 적절한지 직접 확인하는 것이 중요한
대회입니다.

따라서, 참가자들은 작은 규모의 토이 데이터셋(10개 미만)을 사용하여 초기
실험을 진행한 후에 전체 데이터셋에 대한 평가를 진행하는 것을 권장합니다.
실제로 RAG 시스템을 구축할 때에도 이러한 방식이 일반적으로 적용되며,
이를 통해 실험을 더욱 효율적으로 진행할 수 있습니다.

본 대회는 2주간 진행되며 하루 제출 횟수는 5회로 제한됩니다.
