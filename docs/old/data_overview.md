# 데이터 개요

## 학습 데이터 개요

이번 대회는 머신러닝 모델을 학습하는 것보다는 임베딩 생성 모델,
검색엔진, LLM 등을 활용하여 레퍼런스를 잘 추출하고 이를 토대로 얼마나
답변을 잘 생성하는지 판단하는 대회입니다.

따라서 모델 학습을 위한 학습데이터를 별도로 제공하지 않고, 과학 상식
정보를 담고 있는 순수 색인 대상 문서 4200여 개가 제공됩니다.

문서 예시는 다음과 같습니다:

    {
      "docid": "42508ee0-c543-4338-878e-d98c6babee66",
      "src": "ko_mmlu__nutrition__test",
      "content": "건강한 사람이 에너지 균형을 평형 상태로 유지하는 것은 중요합니다..."
    }
    {
      "docid": "7a3e9dc2-2572-4954-82b4-1786e9e48f1f",
      "src": "ko_ai2_arc__ARC_Challenge__test",
      "content": "산꼭대기에서는 중력이 아주 약간 변합니다..."
    }

파일 포맷은 각 줄이 JSON 데이터인 `.jsonl` 파일입니다.

## 학습 데이터 활용

사용자는 임베딩 모델 또는 검색엔진 향상을 위해 문서를 학습용으로 가공해
사용할 수 있습니다.\
예: ColBERT 검색엔진 학습용 pseudo train 데이터셋 생성 등.

## 데이터 다운로드

    wget https://aistages-api-public-prod.s3.amazonaws.com/app/Competitions/000291/data/data.tar.gz

## 평가 데이터 개요

평가 데이터는 RAG 시스템이 자연어 기반 질문에 적합한 레퍼런스를 찾고
답변을 생성하는 능력을 평가합니다.

평가 입력 형식 예시는 다음과 같습니다:

    {"eval_id": 0, "msg": [{"role": "user", "content": "나무의 분류에 대해 조사해 보기 위한 방법은?"}]}
    {"eval_id": 2, "msg": [
      {"role": "user", "content": "기억 상실증 걸리면 너무 무섭겠다."},
      {"role": "assistant", "content": "네 맞습니다."},
      {"role": "user", "content": "어떤 원인 때문에 발생하는지 궁금해."}
    ]}

전체 평가 데이터는 220개이며, 이 중: - 20개는 멀티턴 대화 포함\
- 20개는 일반 대화 메시지 포함

평가 데이터 파일명: `eval.jsonl`
